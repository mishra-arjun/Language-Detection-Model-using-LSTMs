{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROJECT 2 - LSTM\n",
    "\n",
    "## Samuel Norris and Arjun Mishra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This initial section of the project fulfills the basic requirements of developing LSTM models and ultimately being able to predict, with some level of accuracy, the language a given string comes from.  The languages considered in this section are English and French.  We train an English model and a French model.  Then, we predict the probability of seeing a certain string given that it is from an English text as well of the probability of seeing that same string given that it is from a French text.  Whichever log likelihood is greater is the language we predict for that string."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below is based on the code found at https://github.com/fchollet/keras/blob/master/examples/lstm_text_generation.py.  Code is also taken from past homeworks of Sam Norris.  We attempt to include citations of outside sources where they were present in past homeworks, and any omission of such citations is unintentional.  We also used the other recommended blog posts and code, which we do not cite further as we consider this to be assumed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Corpus Length:\t 10746\n",
      "French Corpus Length:\t 12009\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries (some imported later in the code) and read in data\n",
    "\n",
    "from __future__ import print_function\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils.data_utils import get_file\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "\n",
    "path_eng = get_file('eng.txt', origin='https://raw.githubusercontent.com/GT-CSE6240/proj2/master/data/eng.txt')\n",
    "text_eng = open(path_eng).read().lower()\n",
    "print('English Corpus Length:\\t', len(text_eng))\n",
    "\n",
    "path_frn = get_file('frn.txt', origin='https://raw.githubusercontent.com/GT-CSE6240/proj2/master/data/frn.txt')\n",
    "text_frn = open(path_frn).read().lower()\n",
    "print('French Corpus Length:\\t', len(text_frn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Chars:\t 44\n"
     ]
    }
   ],
   "source": [
    "# Get chars from two texts\n",
    "chars_from_eng = sorted(list(set(text_eng)))\n",
    "chars_from_frn = sorted(list(set(text_frn)))\n",
    "\n",
    "# Combine chars from two languages into one chars list\n",
    "#######################\n",
    "# Code between hash lines taken from \n",
    "# http://stackoverflow.com/questions/2151517/pythonic-way-to-create-union-of-all-values-contained-in-multiple-lists\n",
    "results_list = [chars_from_eng, chars_from_frn]\n",
    "chars = list(set().union(*results_list))\n",
    "#######################\n",
    "\n",
    "# Get dictionaries of chars and their index in the chars list\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "print('Total Chars:\\t', len(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English 5-char sequences:\t 10741\n",
      "French 5-char sequences:\t 12004\n"
     ]
    }
   ],
   "source": [
    "# Break up English text into 5 char segments, shifting one char at a\n",
    "# time when making new segments\n",
    "maxlen = 5\n",
    "step = 1\n",
    "char5_strings_eng = []\n",
    "next_chars_eng = []\n",
    "for i in range(0, len(text_eng) - maxlen, step):\n",
    "    char5_strings_eng.append(text_eng[i: i + maxlen])\n",
    "    next_chars_eng.append(text_eng[i + maxlen])\n",
    "print('English 5-char sequences:\\t', len(char5_strings_eng))\n",
    "\n",
    "# Break up French text into 5 char segments, shifting one char at a\n",
    "# time when making new segments\n",
    "maxlen = 5\n",
    "step = 1\n",
    "char5_strings_frn = []\n",
    "next_chars_frn = []\n",
    "for i in range(0, len(text_frn) - maxlen, step):\n",
    "    char5_strings_frn.append(text_frn[i: i + maxlen])\n",
    "    next_chars_frn.append(text_frn[i + maxlen])\n",
    "print('French 5-char sequences:\\t', len(char5_strings_frn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the labels for the datasets\n",
    "# 1=English, 0=French\n",
    "labels_eng = np.array([1]*len(char5_strings_eng))\n",
    "labels_frn = np.array([0]*len(char5_strings_frn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_predict, learning_curve\n",
    "\n",
    "# Do an 80/20 split to get training and test data for both English and French\n",
    "training_data_eng, testing_data_eng, training_labels_eng, testing_labels_eng = train_test_split(\n",
    "        char5_strings_eng, labels_eng, test_size=0.2, random_state=0)\n",
    "\n",
    "training_data_frn, testing_data_frn, training_labels_frn, testing_labels_frn = train_test_split(\n",
    "        char5_strings_frn, labels_frn, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Method to vectorize a dataset\n",
    "def vectorization(char5_strings, maxlen, chars, char_indices, next_chars):\n",
    "    X = np.zeros((len(char5_strings), maxlen, len(chars)), dtype=np.bool)\n",
    "    y = np.zeros((len(char5_strings), len(chars)), dtype=np.bool)\n",
    "    for i, char5_string in enumerate(char5_strings):\n",
    "        for t, char in enumerate(char5_string):\n",
    "            X[i, t, char_indices[char]] = 1\n",
    "        y[i, char_indices[next_chars[i]]] = 1\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_eng, X_train_labels_eng = vectorization(training_data_eng, maxlen, chars, char_indices, next_chars_eng)\n",
    "X_test_eng, X_test_labels_eng = vectorization(testing_data_eng, maxlen, chars, char_indices, next_chars_eng)\n",
    "\n",
    "X_train_frn, X_train_labels_frn = vectorization(training_data_frn, maxlen, chars, char_indices, next_chars_frn)\n",
    "X_test_frn, X_test_labels_frn = vectorization(testing_data_frn, maxlen, chars, char_indices, next_chars_frn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building English model\n",
      "Building French model\n"
     ]
    }
   ],
   "source": [
    "# Build the English model: a single LSTM\n",
    "print('Building English model')\n",
    "model_eng = Sequential()\n",
    "model_eng.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "model_eng.add(Dense(len(chars)))\n",
    "model_eng.add(Activation('softmax'))\n",
    "\n",
    "optimizer = RMSprop(lr=0.01)\n",
    "model_eng.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
    "\n",
    "\n",
    "# Build the French model: a single LSTM\n",
    "print('Building French model')\n",
    "model_frn = Sequential()\n",
    "model_frn.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "model_frn.add(Dense(len(chars)))\n",
    "model_frn.add(Activation('softmax'))\n",
    "\n",
    "model_frn.compile(loss='categorical_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 2s - loss: 3.0107     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 2.9438     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 2.9343     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.9224     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 2.9085     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 2.8860     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 2.8591     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 2.8208     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 2.7727     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 2.7143     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 3\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 2.6491     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 2.5783     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 2.4960     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 2.4160     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 2.3334     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 4\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 2.2515     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 2.1751     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 2.0995     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 2.0312     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.9701     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 5\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.9144     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.8576     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.8135     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.7711     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.7330     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 6\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.7036     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.6719     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.6456     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.6228     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.6004     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 7\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.5852     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.5697     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.5521     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.5374     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.5261     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 8\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.5163     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.5006     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.4965     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.4810     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.4785     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 9\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.4632     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.4567     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.4572     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.4458     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.4432     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 10\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.4384     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.4346     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.4273     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.4188     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.4192     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 11\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.4090     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.4015     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.4032     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3987     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3957     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 12\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3971     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3869     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3854     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3798     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3795     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 13\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3715     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3732     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3668     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3645     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3675     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 14\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3575     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3562     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3523     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3516     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3509     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 15\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3468     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3476     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3454     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3437     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3397     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 16\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3413     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3374     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3355     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3352     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3334     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 17\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3299     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3294     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3262     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3267     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3250     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 18\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3243     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3185     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3180     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3156     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3167     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 19\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3174     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3126     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3111     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3112     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3080     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 20\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3098     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3043     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3062     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3042     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3023     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 21\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3046     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3025     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2988     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3023     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2950     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 22\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2957     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2958     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2952     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2911     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2954     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 23\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2905     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2933     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2883     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2878     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2877     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 24\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2838     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2845     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2879     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2857     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2815     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 25\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2816     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2803     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2765     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2837     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2780     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 26\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2765     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2733     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2743     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2775     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2764     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 27\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2729     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2751     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2717     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2721     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2710     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 28\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2733     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2713     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2688     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2682     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2669     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 29\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2667     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2715     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2658     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2634     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2652     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 30\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2663     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2625     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2636     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2644     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2601     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 31\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2612     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2646     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2597     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2601     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2621     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 32\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2594     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2598     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2578     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2601     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2578     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 33\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2616     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2537     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2553     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2537     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2570     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 34\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2541     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2550     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2517     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2507     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2513     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 35\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2498     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2532     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2483     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2484     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2509     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 36\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2510     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2516     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2504     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2479     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2473     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 37\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2469     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2468     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2479     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2452     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2454     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 38\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2448     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2441     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2445     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2461     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2454     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 39\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2415     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2427     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2442     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2452     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2427     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 40\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2433     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2435     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2400     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2377     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2379     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 41\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2409     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2421     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2418     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2374     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2403     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 42\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2420     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2387     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2375     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2410     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2381     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 43\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2364     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2358     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2398     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2360     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2354     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 44\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2354     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2401     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2345     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2305     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2348     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 45\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2352     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2351     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2327     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2343     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2300     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 46\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2327     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2362     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2311     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2281     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2329     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 47\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2290     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2318     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2317     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2294     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2310     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 48\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2320     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2275     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2303     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2289     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2278     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 49\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2287     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2268     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2276     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2280     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2274     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 50\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2238     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2294     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2256     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2261     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2264     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 51\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2286     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2245     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2267     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2246     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2214     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 52\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2239     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2266     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2247     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2237     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2250     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 53\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2242     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2245     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2239     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2234     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2224     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 54\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2223     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2234     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2224     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2213     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2199     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 55\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2226     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2227     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2188     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2203     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2207     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 56\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2200     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2239     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2191     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2219     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2225     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 57\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2201     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2199     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2159     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2184     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2167     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 58\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2160     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2187     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2186     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2179     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2197     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 59\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2166     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2166     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2187     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2199     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2160     \n"
     ]
    }
   ],
   "source": [
    "# train the English model\n",
    "for iteration in range(1, 60): # Make it 26\n",
    "    print()\n",
    "    print('-' * 50)\n",
    "    print('Iteration', iteration)\n",
    "    model_eng.fit(X_train_eng, X_train_labels_eng,\n",
    "              batch_size=128,\n",
    "              epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 2s - loss: 2.9044     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 1s - loss: 2.8414     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 1s - loss: 2.8344     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 2s - loss: 2.8242     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 1s - loss: 2.8091     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 1s - loss: 2.7915     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 2s - loss: 2.7730     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 1s - loss: 2.7417     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 1s - loss: 2.7056     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 1s - loss: 2.6589     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 3\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 1s - loss: 2.6009     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 2s - loss: 2.5362     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 2s - loss: 2.4649     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 2s - loss: 2.3919     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 1s - loss: 2.3222     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 4\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 1s - loss: 2.2489     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 2s - loss: 2.1837     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 1s - loss: 2.1086     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 2s - loss: 2.0486     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.9876     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 5\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.9442     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.8893     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.8476     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.8119     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.7730     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 6\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.7257     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.7114     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.6758     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.6472     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.6370     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 7\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.6072     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.5948     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.5663     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.5626     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 3s - loss: 1.5489     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 8\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.5273     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.5238     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.5089     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.4978     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.4921     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 9\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.4817     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.4707     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.4648     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.4561     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.4521     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 10\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.4412     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.4355     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.4360     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.4215     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.4206     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 11\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.4122     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.4203     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.3997     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.4069     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.3957     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 12\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.3837     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.3886     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.3869     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.3821     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.3724     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 13\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.3851     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.3742     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.3713     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.3738     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.3619     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 14\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.3646     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.3673     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.3555     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.3588     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.3515     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 15\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.3535     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.3546     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.3445     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.3374     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.3440     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 16\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.3328     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.3393     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.3440     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.3300     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.3386     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 17\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.3302     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.3249     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.3306     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.3275     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.3238     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 18\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.3250     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.3162     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.3158     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.3270     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.3095     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 19\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.3117     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.3156     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.3137     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.3051     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.3125     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 20\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.3113     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.3075     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.3064     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.3029     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.3071     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 21\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2997     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2975     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2995     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2977     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2952     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 22\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2994     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2944     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2954     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2954     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2948     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 23\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2809     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2917     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2860     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2881     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2846     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 24\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2877     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2808     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2819     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2763     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2754     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 25\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2806     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2764     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2801     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2719     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2781     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 26\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2686     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2805     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2816     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2708     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2751     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 27\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2723     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2714     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2732     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2706     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2711     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 28\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2584     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2686     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2697     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2643     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2607     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 29\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2577     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2589     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2674     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2678     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2578     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 30\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2618     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2647     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2615     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2571     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2549     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 31\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2611     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2560     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2594     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2553     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2602     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 32\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2555     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2591     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2565     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2495     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2572     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 33\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2553     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2556     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2494     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2528     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2556     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 34\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2495     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2426     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2551     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2516     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2423     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 35\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2512     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2470     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2495     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2460     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2331     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 36\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2447     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2410     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2389     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2418     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2445     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 37\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2396     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2445     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2379     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2402     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2416     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 38\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2377     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2403     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2440     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2366     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2451     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 39\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2359     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2457     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2385     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2407     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2299     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 40\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2393     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2420     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2411     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2337     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2370     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 41\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2328     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2366     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2349     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2373     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2370     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 42\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2319     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2312     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2337     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2416     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2368     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 43\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2277     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2327     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2300     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2295     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2294     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 44\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2273     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2335     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2311     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2293     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2284     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 45\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2307     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2307     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2272     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2335     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2283     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 46\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2240     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2205     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2253     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2260     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2314     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 47\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2268     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2253     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2207     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2203     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2300     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 48\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2209     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2217     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2281     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2163     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2272     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 49\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2201     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2216     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2194     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2240     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2255     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 50\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2232     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2210     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2214     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2203     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2174     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 51\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2243     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2204     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2184     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2229     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2209     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 52\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2218     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2194     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2141     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2207     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2209     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 53\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2096     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2162     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2229     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2142     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2187     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 54\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2086     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2111     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2175     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2207     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2165     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 55\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2125     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2198     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2143     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2129     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2096     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 56\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2152     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2160     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2145     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2120     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2178     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 57\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2030     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2119     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2114     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2094     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2166     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 58\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2118     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2129     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2096     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2116     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2071     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 59\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2143     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2106     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2104     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2127     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2111     \n"
     ]
    }
   ],
   "source": [
    "# train the French model\n",
    "for iteration in range(1, 60): # Make this 26\n",
    "    print()\n",
    "    print('-' * 50)\n",
    "    print('Iteration', iteration)\n",
    "    model_frn.fit(X_train_frn, X_train_labels_frn,\n",
    "              batch_size=128,\n",
    "              epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create the 200 test data\n",
    "test_data_200 = np.zeros((200, maxlen, len(chars)), dtype=np.bool)\n",
    "\n",
    "# Pick 100 substrings at random from each language\n",
    "eng_test_indices = np.random.randint(0, X_test_eng.shape[0], size=100)\n",
    "frn_test_indices = np.random.randint(0, X_test_frn.shape[0], size=100)\n",
    "\n",
    "# Fill the data\n",
    "test_data_200[:100] = X_test_eng[eng_test_indices,:,:]\n",
    "test_data_200[100:] = X_test_frn[frn_test_indices,:,:]\n",
    "\n",
    "# Create the labels\n",
    "test_labels_200 = np.concatenate(([1]*100, [0]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Vectorize test string\n",
    "def test_vectorization(test_string, maxlen, chars, char_indices):\n",
    "    # Create array to handle broken up test string\n",
    "    test_string_data = []\n",
    "    \n",
    "    # Break up test string\n",
    "    for ind in range(min(maxlen, len(test_string))):\n",
    "        test_string_data.append(test_string[:ind])\n",
    "   \n",
    "    # Create X\n",
    "    X = np.zeros((len(test_string_data), maxlen, len(chars)), dtype=np.bool)\n",
    "    for i, test_string_entry in enumerate(test_string_data):\n",
    "        for t, char in enumerate(test_string_entry):\n",
    "            X[i, t, char_indices[char]] = 1\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/5 [=====>........................] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "test_predict_200 = np.zeros(200)\n",
    "test_y_hat_200 = np.zeros(200)\n",
    "\n",
    "for t in range(test_data_200.shape[0]):\n",
    "    letter_string = ''\n",
    "    for letter in range(maxlen):\n",
    "        letter_ind = np.where(test_data_200[t,letter,:]==1)[0][0]\n",
    "        letter_string += chars[letter_ind]\n",
    "    letter_string_vect = test_vectorization(letter_string, maxlen, chars, char_indices)\n",
    "    \n",
    "    test_predict_eng = model_eng.predict(letter_string_vect, batch_size=1, verbose=1)\n",
    "    test_predict_frn = model_frn.predict(letter_string_vect, batch_size=1, verbose=1)\n",
    "    total_prob_eng = 1\n",
    "    total_prob_frn = 1\n",
    "    for p in range(len(test_predict_eng)):\n",
    "        \"\"\"if len(np.where(test_data_200[t,p,:]==1)[0]) == 0:\n",
    "            print('BREAK')\n",
    "            break\"\"\"\n",
    "        char_ind = np.where(test_data_200[t,p,:]==1)[0][0]\n",
    "        # English probability\n",
    "        char_prob_eng = test_predict_eng[p, char_ind]\n",
    "        total_prob_eng *= char_prob_eng\n",
    "        # French probability\n",
    "        char_prob_frn = test_predict_frn[p, char_ind]\n",
    "        total_prob_frn *= char_prob_frn\n",
    "    prediction = 1 if (np.log(total_prob_eng) > np.log(total_prob_frn)) else 0\n",
    "    test_predict_200[t] = prediction\n",
    "    test_y_hat_200[t] = np.log(total_prob_eng) - np.log(total_prob_frn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.62\n"
     ]
    }
   ],
   "source": [
    "accuracy_vect = np.nonzero(test_labels_200 - test_predict_200)\n",
    "accuracy = 1 - (len(accuracy_vect[0]) / 200.)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAoMAAAFqCAYAAABhzVBZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwAyDkiRJBWYYlCRJKjDDoCRJUoH9/w1ASeecJDnFAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x146640a20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Code from\n",
    "# http://stackoverflow.com/questions/42894871/how-to-plot-multiple-roc-curves-in-one-plot-with-legend-and-auc-scores-in-python\n",
    "\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "plt.figure(0).clf()\n",
    "\n",
    "auc = metrics.roc_auc_score(test_labels_200, test_y_hat_200)\n",
    "fpr, tpr, thresholds = metrics.roc_curve(test_labels_200, test_y_hat_200)\n",
    "plt.semilogx(basex = math.e)\n",
    "plt.plot(fpr, tpr, label=\"AUC=\"+str(auc))\n",
    "#plt.plot([0, 1], [0, 1], color='gray')\n",
    "\n",
    "plt.legend(loc=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our Model Performance\n",
    "Given the small size of the training data (files are 11-12 KB, and in one of the recommended blog posts for this assingment, Karpathy refers to a 1MB text file as small), our performance seems pretty good.  In testing with this model, accuracies between 55% and 65.5% were common.  The AUC also seems respectable.  The minor variations in model performance are likely due to the random sampling of 100 strings per language from the test data.  Overall, I would say the model performs well.\n",
    "***\n",
    "\n",
    "### Discussion of why LSTM is good for language detection compared to other models\n",
    "We wanted to point out the merits of LSTMs over other models.  The following paragraph is taken directly from https://arxiv.org/abs/1308.0850v5.\n",
    "\n",
    "_\"RNNs are fuzzy in the sense that they do not use exact templates from\n",
    "the training data to make predictions, but ratherlike other neural networks\n",
    "use their internal representation to perform a high-dimensional interpolation\n",
    "between training examples. This distinguishes them from n-gram models and\n",
    "compression algorithms such as Prediction by Partial Matching [5], whose predictive\n",
    "distributions are determined by counting exact matches between the\n",
    "recent history and the training set. The resultwhich is immediately apparent from the samples in this paperis that RNNs (unlike template-based algorithms)\n",
    "synthesise and reconstitute the training data in a complex way, and\n",
    "rarely generate the same thing twice. Furthermore, fuzzy predictions do not suffer\n",
    "from the curse of dimensionality, and are therefore much better at modelling\n",
    "real-valued or multivariate data than exact matches.\n",
    " As well as diminishing\n",
    "their ability to model long-range structure, this amnesia makes them prone to\n",
    "instability when generating sequences. The problem (common to all conditional\n",
    "generative models) is that if the networks predictions are only based on the last\n",
    "few inputs, and these inputs were themselves predicted by the network, it has\n",
    "little opportunity to recover from past mistakes. Having a longer memory has\n",
    "a stabilising effect, because even if the network cannot make sense of its recent\n",
    "history, it can look further back in the past to formulate its predictions.\"_\n",
    "***\n",
    "\n",
    "### Three alternatives to language detection\n",
    "### 1\n",
    "The n-gram approach: The n-gram model is a (n-1) order Markov model which uses the previous n-1 'grams' to predict the next gram. These grams can be words, syllables, phenomes etc. The model makes an independence assumption i.e. the nth gram only depends on the previous n-1 grams, to solve the Markov model effectively. For language detection, we could train n-gram models in different languages and finally feed it new paragraphs to arrive at the probability of the paragraph belonging to a particular language. The probability will be based on how often n-grams from a particular language appear in the new text. This is like using an expectation maximization algorithm.\n",
    "\n",
    "\n",
    "Some of the advantages of the n-gram approach are:\n",
    "1. It does not require building up a huge dictionary like the bag of words approach or other profiling algorithms. Thus the long time to search through the library is avoided.\n",
    "2. Unlike the vanilla BOW and other profiling models, it can find structure and patterns in the language. For example, it might find that it is common for the letter 'u' to follow the letter 'q' in English.\n",
    "3. This model is robust to getting new words in a paragraph, compared to what it was trained on.\n",
    "\n",
    "The n-gram approach struggles in the following areas:\n",
    "1. Language identification on very short texts - The n-gram model is not able to develop sufficient context understanding in short datasets to provide good predictions.\n",
    "2. A n-gram model would also provide us poor accuracy when the text we are analyzing comprise of multiple languages. It wouldn't be able to correctly handle texts of an unknown language.\n",
    "3. As the name suggests, we can use different length 'grams' in our model. We can feed bigrams, trigrams and quadgrams at the same time for a more stable model. n-grams also use words from either side of a particular word so the context developed by the model is much stronger. The n can also be anything - words, syllables, letters etc. and we can customize accordingly.\n",
    "\n",
    "### 2\n",
    "The dictionary approach: The most obvious way that anyone can think of when doing language detection is the formation of a\n",
    "word dictionary for each language. A list of common words used in a language will be the most simple and effective corpus for detecting a particular language. For example, articles like a, an, the would be some of the words for the English language.\n",
    "Depending on the type of corpus we have created, we can use a profiling algorithm that best works with it.\n",
    "The most straightforward use case for this approach is using the most common words in the language as the corpus. Once the corpus is formed, we find the distance between the standard corpus and our target document, which will be equal to the sum of differences between the frequencies of matching words.\n",
    "A variation of this model could be using character sets instead of formulated words. The idea is to map fequencies of the character sets and identify commonly used sets.\n",
    "\n",
    "These algorithms suffer from the following drawbacks:\n",
    "\n",
    "Since the frequency of matching words is very less, the algorithm cannot efficiently work with small texts having few sentences. It needs a lot of text for accurate match.\n",
    "\n",
    "It cannot detect word boundaries for languages having compound sentences, and those having no word dividers like spaces or punctuation marks.\n",
    "\n",
    "It is difficult to differentiate two languages having similar character frequencies.\n",
    "\n",
    "Some of the pro's of this approach are:\n",
    "\n",
    "They are fairly simple to develop and very easy to use. Once a versatile corpora has been created for each language, large paragraphs can easily be classified into their respective languages without a lot of effort.\n",
    "\n",
    "It is very easy to understand what this method is doing. Compared to highly complex models like LSTMs, this approach is highly simplistic.\n",
    "\n",
    "### 3\n",
    "A third alternative for language identification is also based on the n-gram approach but also applies a machine learning model on top of it. First we count character n-gram occurrences in a given text, for n up to some maximum length, and use these counts as\n",
    "the features in a classification model. SVMs are appropriate in this problem as they can take a large number of features and learn to weigh them appropriately. The standard n-gram model is a Markov model using the text to map the probabilities of the next occurence and then appropriately assigning it to a language. A classification model will use the counts of the n-grams to directly arrive at a classification of the language when already trained on a corpus of documents.\n",
    "\n",
    "The main advantages of this approach are:\n",
    "1. We can use features apart from just the n-gram counts. Some examples of features might be - using the word count in a document, the average character length of words etc. We can also incorporate distance and similarity features. For example, we can have a document as the standard English document and we can measure the Jaccard similarity/the manhattan distance/the Euclidean distance between this standard and our new document. These measures can again be incorporated in the final classification model. Thus, this model will almost be an overlapping model between the two previous approaches - n-gram and dictionary based.\n",
    "\n",
    "2. The accuracy of the n-gram approach highly depends on the length of the text corpus. However, a SVM model for example would have robust decision boundaries that won't depend on the length as much and would still be able to classify smaller length documents well.\n",
    "\n",
    "Potential disadvantages of such a model can be:\n",
    "If the new document being fed for classification has n-grams on which the model hasn't been trained on previously, we will have to remove those n-grams. Those n-grams could however prove to be important.\n",
    "Training these models in terms of their speed can also be a challenge. A corpus containing a very large number of features can take time to train and predict.\n",
    "A third challenge can be choosing the best classification model. SVMs have proven to work well in such a scenario. However, for SVMs, choosing the best kernel and optiizing other parameters is a challenge.\n",
    "\n",
    "\n",
    "### Another alternative for language modeling is:\n",
    "Using a Hidden Markov Model. A hidden Markov model is a Markov model with unobserved states. While the state is not directly visible, the output based on the state can be observed. \"Hidden\" here referes to the state sequence and not the parameters of the model. Each state has a probability distribution over the output.\n",
    "To understand this concept for language identification, we will take an example based on the same data that we have been given:\n",
    "The Hidden Markov model M(V, A, B) depends on three inputs: V is a vector containing the probability v(n) that the model is initially in state n. A is the matrix of transition probabilities, and B is the matrix of output probabilities. Suppose we feed the English and French datasets given to us into this Markov model. We will get two matrices of transition probabilities (A) corresponding to each language corpus. Now, when we input a new word to each model, suppose \"ver\", we will get a probability output of which model is likely to produce \"se\" after that (considering that the whole word was \"verse\"). If the output probabilities are mapped to a gaussian distribution, we can use a gaussian mixture model to get the probability of the word lying in either language. The only difference of a Hidden Markov Model from a n-gram model (Markov model) is that we also map the previous state to a probability distribution instead of knowing it outright.\n",
    "***\n",
    "\n",
    "### 5 ways to improve this model are:\n",
    "\n",
    "1. Currently, we are breaking-up our raw data into fixed size sequences letting the LSTM learn random mappings of 5 characters to 1 character. We can alter batch size to offer more sequence to the network, but only during training. LSTMs are meant ot be exposed to the entire sequence and then learn the inter-dependencies. We can do this in Keras by making the LSTM layers stateful. A stateful LSTM internalizes the states obtained after processing a batch of samples and reuses these states as initial states for the samples of the next batch. Thus, the network gains a memory and gets much better at retaining the past interdependencies it found. This allows the network to learn larger sequences and also keeps computational complexity manageable. - May result in a better model and better prediction. \n",
    "\n",
    "2. In our current model, we are feeding documents to the LSTM model in the correct order. Thus the LSTM is learning based on the previous words/characters, what the next character should be. However, to distinguish between two languages, we can hypothesize that the words are structured differently from the left and the right. This is where a bi-directional model comes in. A bi-directional LSTM would learn the language representation from both directions. For example, to learn the next three characters in the word \"Universe\" when starting with \"uni\", a forward LSTM would predict the probability of seeing \"ver\" based on \"uni\" coming first. However in the backward direction, the LSTM would map the proabability of finding \"ive\" based on finding \"rse\". This can help us distinguish between words in the languages in a much better way compared to a single LSTM. - May result in a better model and prediction.\n",
    "\n",
    "3. The model that we have implemented has a single LSTM layer. While a LSTM is a RNN and has a loop for information flow within it, we can also implement a stacked LSTM with multiple LSTM layers. Multiple LSTM layers help us introduce greater model complexity. One lSTM layer feeds into the second and so on. If the input coming into a subsequent LSTM layer is from another LSTM layer, a highly complex feature representation can be created. As each LSTM receives feedback from its previous steps, a stacked LSTM model will describe intricate input patterns at each layer. - Would result in an increase in training time but may also give better predictions.\n",
    "\n",
    "4. The datasets (English and French) we have used for this model has ~10k number of 5 character consecutive sequences. This is a very small dataset. If we take a larger dataset, our LSTM will be able to decipher representations of the language in a much better manner. Each and every new sentence might hold new differences between English and French which the model might be able to capture if it had more training examples. Also, as we know that the LSTM works based on memory, a larger dataset will allow the LSTM to successfully \"store and recall\" more number of rules/patterns it finds in the data. - Would result in an increase in training time but may also give better predictions.\n",
    "\n",
    "5. Using variable length inputs to the LSTM: In our model, we have used 5 character segments from the text. There is no specific scientific reason to use this length of segments.  Building upon the n-gram idea, we can use multiple length character segments to train our LSTM. This will allow our model to learn random subsequences of the alphabet and give a more generic result. For example, learning the word \"TEXT\" in a bi-character sequence (te, ex, xt) will give different information to the model compared to learning it in a tr-character sequence (text, ext). This will also result in more intricate learning when we feed texts from two different languages to the model. - May result in a better model and better prediction. \n",
    "\n",
    "6. Fine tuning the model: There are a lot of other parameter combinations that we can try to tune. We can add more feed-forward layers, change the optimizer, the loss function etc.\n",
    "\n",
    "7. Using GPUs - LSTMs are computationally expensive models which process a lot of informatino in parallel. GPUs have a lot of processing cores in them. This makes training deep models on GPUs highly efficient and quicker. To implement training with GPUs, we need a supported NVidia graphics card and the NVidia CUDA toolkit. - Should decrease training time but would not result in model improvement.\n",
    "\n",
    "We will implement some of these ideas in the next section.\n",
    "***\n",
    "\n",
    "### References:\n",
    "* http://bioinf.jku.at/publications/older/2604.pdf\n",
    "* https://arxiv.org/pdf/1308.0850.pdf\n",
    "* https://www.tutorialspoint.com/tika/tika_language_detection.htm\n",
    "* http://machinelearningmastery.com/understanding-stateful-lstm-recurrent-neural-networks-python-keras/\n",
    "* http://colah.github.io/posts/2015-08-Understanding-LSTMs/\n",
    "* https://en.wikipedia.org/wiki/N-gram\n",
    "* http://stackoverflow.com/questions/7670427/how-does-language-detection-work\n",
    "* https://en.wikipedia.org/wiki/Language_identification\n",
    "* https://stats.stackexchange.com/questions/144900/why-is-n-gram-used-in-text-language-identification-instead-of-words\n",
    "* http://www.cs.toronto.edu/~aditya/publications/langid.pdf\n",
    "* https://en.wikipedia.org/wiki/Hidden_Markov_model\n",
    "* https://www.doc.ic.ac.uk/~nd/surprise_96/journal/vol2/ur1/article2.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra Credit - English, French, Russian, German, and Greek"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I wanted to see how well LSTMs performed with a larger number of languages, some of which are very different from each other.  I got the text samples for additional languages through the blog referenced in the project assignment PDF.  I predict as the language for any given text the language with the largest log likelihood of seeing that text, given a particular language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Corpus Length:\t 10746\n",
      "French Corpus Length:\t 12009\n",
      "Russian Corpus Length:\t 11930\n",
      "German Corpus Length:\t 12078\n",
      "Greek Corpus Length:\t 12547\n"
     ]
    }
   ],
   "source": [
    "path_eng = get_file('eng.txt', origin='https://raw.githubusercontent.com/GT-CSE6240/proj2/master/data/eng.txt')\n",
    "text_eng = open(path_eng).read().lower()\n",
    "print('English Corpus Length:\\t', len(text_eng))\n",
    "\n",
    "path_frn = get_file('frn.txt', origin='https://raw.githubusercontent.com/GT-CSE6240/proj2/master/data/frn.txt')\n",
    "text_frn = open(path_frn).read().lower()\n",
    "print('French Corpus Length:\\t', len(text_frn))\n",
    "\n",
    "path_rus = 'data/rus.txt'\n",
    "text_rus = open(path_rus).read().lower()\n",
    "print('Russian Corpus Length:\\t', len(text_rus))\n",
    "\n",
    "path_ger = 'data/ger.txt'\n",
    "text_ger = open(path_ger).read().lower()\n",
    "print('German Corpus Length:\\t', len(text_ger))\n",
    "\n",
    "path_grk = 'data/grk.txt'\n",
    "text_grk = open(path_grk).read().lower()\n",
    "print('Greek Corpus Length:\\t', len(text_grk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Chars:\t 115\n"
     ]
    }
   ],
   "source": [
    "# Get chars from five texts\n",
    "chars_from_eng = sorted(list(set(text_eng)))\n",
    "chars_from_frn = sorted(list(set(text_frn)))\n",
    "chars_from_rus = sorted(list(set(text_rus)))\n",
    "chars_from_ger = sorted(list(set(text_ger)))\n",
    "chars_from_grk = sorted(list(set(text_grk)))\n",
    "\n",
    "# Combine chars from five languages into one chars list\n",
    "#######################\n",
    "# Code between hash lines taken from \n",
    "# http://stackoverflow.com/questions/2151517/pythonic-way-to-create-union-of-all-values-contained-in-multiple-lists\n",
    "results_list = [chars_from_eng, chars_from_frn, chars_from_rus, chars_from_ger, chars_from_grk]\n",
    "chars = list(set().union(*results_list))\n",
    "#######################\n",
    "\n",
    "# Get dictionaries of chars and their index in the chars list\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "print('Total Chars:\\t', len(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English 5-char sequences:\t 10741\n",
      "French 5-char sequences:\t 12004\n",
      "Russian 5-char sequences:\t 11925\n",
      "German 5-char sequences:\t 12073\n",
      "Greek 5-char sequences:\t 12542\n"
     ]
    }
   ],
   "source": [
    "# Break up English text into 5 char segments, shifting one char at a\n",
    "# time when making new segments\n",
    "maxlen = 5\n",
    "step = 1\n",
    "char5_strings_eng = []\n",
    "next_chars_eng = []\n",
    "for i in range(0, len(text_eng) - maxlen, step):\n",
    "    char5_strings_eng.append(text_eng[i: i + maxlen])\n",
    "    next_chars_eng.append(text_eng[i + maxlen])\n",
    "print('English 5-char sequences:\\t', len(char5_strings_eng))\n",
    "\n",
    "# Break up French text into 5 char segments, shifting one char at a\n",
    "# time when making new segments\n",
    "maxlen = 5\n",
    "step = 1\n",
    "char5_strings_frn = []\n",
    "next_chars_frn = []\n",
    "for i in range(0, len(text_frn) - maxlen, step):\n",
    "    char5_strings_frn.append(text_frn[i: i + maxlen])\n",
    "    next_chars_frn.append(text_frn[i + maxlen])\n",
    "print('French 5-char sequences:\\t', len(char5_strings_frn))\n",
    "\n",
    "# Break up Russian text into 5 char segments, shifting one char at a\n",
    "# time when making new segments\n",
    "maxlen = 5\n",
    "step = 1\n",
    "char5_strings_rus = []\n",
    "next_chars_rus = []\n",
    "for i in range(0, len(text_rus) - maxlen, step):\n",
    "    char5_strings_rus.append(text_rus[i: i + maxlen])\n",
    "    next_chars_rus.append(text_rus[i + maxlen])\n",
    "print('Russian 5-char sequences:\\t', len(char5_strings_rus))\n",
    "\n",
    "# Break up German text into 5 char segments, shifting one char at a\n",
    "# time when making new segments\n",
    "maxlen = 5\n",
    "step = 1\n",
    "char5_strings_ger = []\n",
    "next_chars_ger = []\n",
    "for i in range(0, len(text_ger) - maxlen, step):\n",
    "    char5_strings_ger.append(text_ger[i: i + maxlen])\n",
    "    next_chars_ger.append(text_ger[i + maxlen])\n",
    "print('German 5-char sequences:\\t', len(char5_strings_ger))\n",
    "\n",
    "# Break up Greek text into 5 char segments, shifting one char at a\n",
    "# time when making new segments\n",
    "maxlen = 5\n",
    "step = 1\n",
    "char5_strings_grk = []\n",
    "next_chars_grk = []\n",
    "for i in range(0, len(text_grk) - maxlen, step):\n",
    "    char5_strings_grk.append(text_grk[i: i + maxlen])\n",
    "    next_chars_grk.append(text_grk[i + maxlen])\n",
    "print('Greek 5-char sequences:\\t', len(char5_strings_grk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the labels for the datasets\n",
    "# 1=English, 0=French, 2=Russian, 3=German, 4=Greek\n",
    "labels_frn = np.array([0]*len(char5_strings_frn))\n",
    "labels_eng = np.array([1]*len(char5_strings_eng))\n",
    "labels_rus = np.array([2]*len(char5_strings_rus))\n",
    "labels_ger = np.array([3]*len(char5_strings_ger))\n",
    "labels_grk = np.array([4]*len(char5_strings_grk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Do an 80/20 split to get training and test data for each language\n",
    "training_data_eng, testing_data_eng, training_labels_eng, testing_labels_eng = train_test_split(\n",
    "        char5_strings_eng, labels_eng, test_size=0.2, random_state=0)\n",
    "\n",
    "training_data_frn, testing_data_frn, training_labels_frn, testing_labels_frn = train_test_split(\n",
    "        char5_strings_frn, labels_frn, test_size=0.2, random_state=0)\n",
    "\n",
    "training_data_rus, testing_data_rus, training_labels_rus, testing_labels_rus = train_test_split(\n",
    "        char5_strings_rus, labels_rus, test_size=0.2, random_state=0)\n",
    "\n",
    "training_data_ger, testing_data_ger, training_labels_ger, testing_labels_ger = train_test_split(\n",
    "        char5_strings_ger, labels_ger, test_size=0.2, random_state=0)\n",
    "\n",
    "training_data_grk, testing_data_grk, training_labels_grk, testing_labels_grk = train_test_split(\n",
    "        char5_strings_grk, labels_grk, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Vectorization method defined above\n",
    "\n",
    "X_train_eng, X_train_labels_eng = vectorization(training_data_eng, maxlen, chars, char_indices, next_chars_eng)\n",
    "X_test_eng, X_test_labels_eng = vectorization(testing_data_eng, maxlen, chars, char_indices, next_chars_eng)\n",
    "\n",
    "X_train_frn, X_train_labels_frn = vectorization(training_data_frn, maxlen, chars, char_indices, next_chars_frn)\n",
    "X_test_frn, X_test_labels_frn = vectorization(testing_data_frn, maxlen, chars, char_indices, next_chars_frn)\n",
    "\n",
    "X_train_rus, X_train_labels_rus = vectorization(training_data_rus, maxlen, chars, char_indices, next_chars_rus)\n",
    "X_test_rus, X_test_labels_rus = vectorization(testing_data_rus, maxlen, chars, char_indices, next_chars_rus)\n",
    "\n",
    "X_train_ger, X_train_labels_ger = vectorization(training_data_ger, maxlen, chars, char_indices, next_chars_ger)\n",
    "X_test_ger, X_test_labels_ger = vectorization(testing_data_ger, maxlen, chars, char_indices, next_chars_ger)\n",
    "\n",
    "X_train_grk, X_train_labels_grk = vectorization(training_data_grk, maxlen, chars, char_indices, next_chars_grk)\n",
    "X_test_grk, X_test_labels_grk = vectorization(testing_data_grk, maxlen, chars, char_indices, next_chars_grk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building English model\n",
      "Building French model\n",
      "Building Russian model\n",
      "Building German model\n",
      "Building Greek model\n"
     ]
    }
   ],
   "source": [
    "# Build the English model: a single LSTM\n",
    "print('Building English model')\n",
    "model_eng = Sequential()\n",
    "model_eng.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "model_eng.add(Dense(len(chars)))\n",
    "model_eng.add(Activation('softmax'))\n",
    "\n",
    "optimizer = RMSprop(lr=0.01)\n",
    "model_eng.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
    "\n",
    "\n",
    "# Build the French model: a single LSTM\n",
    "print('Building French model')\n",
    "model_frn = Sequential()\n",
    "model_frn.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "model_frn.add(Dense(len(chars)))\n",
    "model_frn.add(Activation('softmax'))\n",
    "\n",
    "model_frn.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
    "\n",
    "\n",
    "# Build the Russian model: a single LSTM\n",
    "print('Building Russian model')\n",
    "model_rus = Sequential()\n",
    "model_rus.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "model_rus.add(Dense(len(chars)))\n",
    "model_rus.add(Activation('softmax'))\n",
    "\n",
    "model_rus.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
    "\n",
    "\n",
    "# Build the German model: a single LSTM\n",
    "print('Building German model')\n",
    "model_ger = Sequential()\n",
    "model_ger.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "model_ger.add(Dense(len(chars)))\n",
    "model_ger.add(Activation('softmax'))\n",
    "\n",
    "model_ger.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
    "\n",
    "\n",
    "# Build the Greek model: a single LSTM\n",
    "print('Building Greek model')\n",
    "model_grk = Sequential()\n",
    "model_grk.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "model_grk.add(Dense(len(chars)))\n",
    "model_grk.add(Activation('softmax'))\n",
    "\n",
    "model_grk.compile(loss='categorical_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 3s - loss: 3.0477     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 2.9497     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 2.9407     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 2.9292     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 2.9419     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 2.9053     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 2.8853     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.8527     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.8135     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.7669     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 3\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.7106     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.6441     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 2.5724     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 2.4956     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 2.4202     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 4\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 2.3361     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 2.2644     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.1930     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.1243     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.0462     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 5\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.9963     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.9353     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.8768     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.8343     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.7917     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 6\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.7531     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.7173     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.6861     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.6594     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.6315     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 7\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.6151     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.5876     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.5818     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.5616     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.5442     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 8\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.5317     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.5163     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.5018     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.4960     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.4867     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 9\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.4785     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.4673     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.4613     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.4567     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.4493     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 10\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.4398     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.4360     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.4267     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.4254     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.4275     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 11\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.4147     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.4092     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.4068     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.4005     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3999     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 12\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3892     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3916     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3857     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3830     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3838     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 13\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3715     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3710     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3690     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3637     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3676     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 14\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3617     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3586     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3554     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3478     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3514     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 15\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3503     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3441     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3466     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3479     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.3394     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 16\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3390     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3394     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3311     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.3286     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.3344     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 17\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3228     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.3312     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3261     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3227     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3242     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 18\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3230     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3159     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3245     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3163     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3136     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 19\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3128     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3116     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3107     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3101     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3071     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 20\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3053     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3056     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3051     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3045     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2993     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 21\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3028     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2961     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2996     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2983     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2977     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 22\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2959     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2905     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2923     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2923     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2908     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 23\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2903     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2868     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2850     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2849     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2870     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 24\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2870     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2842     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2842     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2804     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2846     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 25\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2816     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2842     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2804     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2784     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2781     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 26\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2775     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2767     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2759     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2755     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2725     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 27\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2702     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2728     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2694     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2729     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2720     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 28\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2667     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2717     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2705     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2633     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2680     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 29\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2648     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2649     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2642     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2653     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2675     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 30\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2602     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2625     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2637     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2647     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2628     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 31\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2586     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2601     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2594     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2613     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2587     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 32\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2574     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2575     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2590     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2579     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2532     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 33\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2576     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2560     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2529     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2523     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2521     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 34\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2561     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2508     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2531     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2536     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2501     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 35\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2492     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2493     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2502     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2468     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2495     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 36\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2483     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2478     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2466     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2508     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2422     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 37\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2454     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2470     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2459     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2426     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2446     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 38\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2442     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2429     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2427     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2411     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2420     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 39\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2448     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2423     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2415     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2415     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2425     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 40\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2360     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2385     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2409     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2419     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2375     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 41\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2383     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2346     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2401     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2369     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2372     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 42\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2342     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2390     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2363     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2376     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2351     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 43\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2374     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2340     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2353     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2346     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2348     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 44\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2296     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2359     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2304     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2330     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2294     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 45\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2316     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2345     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2320     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2283     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2306     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 46\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2312     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2324     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2297     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2280     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2295     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 47\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2283     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2303     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2313     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2283     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2293     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 48\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2262     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2267     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2290     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2290     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2252     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 49\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2274     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2249     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2283     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2267     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2273     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 50\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2217     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2282     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2273     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2236     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2245     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 51\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2221     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2207     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2228     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2229     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2239     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 52\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2232     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2226     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2228     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2225     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2232     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 53\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2208     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2238     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2201     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2225     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2266     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 54\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2191     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2191     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2213     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2186     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2182     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 55\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2196     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2172     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2190     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2194     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2183     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 56\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2201     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2149     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2178     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2188     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2188     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 57\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2216     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2187     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2158     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2154     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2176     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 58\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2145     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2150     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2178     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2186     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2172     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 59\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2169     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2154     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2157     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2161     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2136     \n"
     ]
    }
   ],
   "source": [
    "# train the English model\n",
    "for iteration in range(1, 60): # Make it 26\n",
    "    print()\n",
    "    print('-' * 50)\n",
    "    print('Iteration', iteration)\n",
    "    model_eng.fit(X_train_eng, X_train_labels_eng,\n",
    "              batch_size=128,\n",
    "              epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 3s - loss: 2.9424     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 1s - loss: 2.8449     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 2s - loss: 2.8366     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 2s - loss: 2.8294     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 2s - loss: 2.8178     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 2s - loss: 2.8027     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 2s - loss: 2.7818     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 2s - loss: 2.7565     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 2s - loss: 2.7221     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 2s - loss: 2.6844     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 3\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 2s - loss: 2.6335     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 2s - loss: 2.5811     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 2s - loss: 2.5235     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 1s - loss: 2.4577     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 1s - loss: 2.3847     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 4\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 1s - loss: 2.3160     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 1s - loss: 2.2511     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 1s - loss: 2.1824     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 1s - loss: 2.1159     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 1s - loss: 2.0567     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 5\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.9989     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.9447     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.8957     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.8496     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.8132     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 6\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.7647     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.7337     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.7064     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.6829     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.6541     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 7\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.6198     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.6204     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.5944     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.5747     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.5639     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 8\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.5425     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.5371     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.5287     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.5015     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.5047     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 9\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.4858     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.4765     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.4689     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.4633     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.4466     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 10\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.4419     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.4416     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.4351     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.4364     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.4279     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 11\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.4139     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.4222     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.4051     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.4034     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.3984     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 12\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.3962     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.3913     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.3854     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.3787     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.3789     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 13\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.3790     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.3667     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.3641     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.3648     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.3636     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 14\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.3672     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.3521     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.3539     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.3516     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.3515     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 15\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.3503     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.3487     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.3514     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.3462     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.3510     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 16\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.3363     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.3388     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.3361     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.3328     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.3330     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 17\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.3241     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.3301     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.3224     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.3271     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.3158     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 18\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.3203     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.3156     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.3181     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.3155     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.3130     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 19\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.3175     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.3178     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.3069     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.3100     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.3023     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 20\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.3008     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.3026     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.3033     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2997     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.3091     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 21\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2975     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2989     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2943     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2987     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2906     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 22\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2938     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2942     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2922     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2810     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2956     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 23\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2942     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2869     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2878     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2914     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2756     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 24\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2862     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2869     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2788     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2804     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2815     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 25\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2840     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2847     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2790     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2841     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2772     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 26\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2714     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2747     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2714     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2773     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2756     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 27\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2698     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 3s - loss: 1.2758     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2747     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2717     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2691     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 28\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2699     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2685     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2651     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2694     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2705     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 29\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2657     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2663     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2625     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2629     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2624     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 30\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2554     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2591     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2580     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2621     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2608     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 31\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2552     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2615     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2622     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2593     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2541     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 32\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2564     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2456     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2571     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2454     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2598     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 33\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2480     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2459     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2538     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2490     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2488     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 34\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2524     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2504     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2544     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2549     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2468     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 35\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2520     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2487     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2435     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2451     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2435     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 36\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2509     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2370     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2532     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2449     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2420     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 37\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2425     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2465     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2455     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2358     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2378     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 38\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2406     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2376     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2395     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2383     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2383     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 39\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2402     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2354     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2401     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2419     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2338     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 40\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2361     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2324     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2395     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2372     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2316     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 41\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2320     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2346     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2232     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2370     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2329     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 42\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2357     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2323     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2423     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2307     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2346     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 43\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2326     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2347     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 3s - loss: 1.2314     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2282     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2261     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 44\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2300     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2366     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2267     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2273     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2271     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 45\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2334     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2246     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2334     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2259     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2238     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 46\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2248     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2264     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2272     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2278     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2234     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 47\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2257     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2313     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2311     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2287     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2216     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 48\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2251     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2282     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2145     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2215     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2219     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 49\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2247     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2196     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2231     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2215     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2162     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 50\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2233     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2215     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2246     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2248     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2212     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 51\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2159     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2204     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2237     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2182     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2201     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 52\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2199     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2215     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2118     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2206     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2260     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 53\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2177     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2126     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2226     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2166     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2170     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 54\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2152     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2190     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2161     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2180     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2207     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 55\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2124     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2175     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2228     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2173     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2203     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 56\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2092     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2208     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2122     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2108     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2133     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 57\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2176     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2125     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2093     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2087     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2123     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 58\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2117     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2142     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2153     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2110     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2127     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 59\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 1s - loss: 1.2107     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2168     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2136     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2093     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2155     \n"
     ]
    }
   ],
   "source": [
    "# train the French model\n",
    "for iteration in range(1, 60): # Make this 26\n",
    "    print()\n",
    "    print('-' * 50)\n",
    "    print('Iteration', iteration)\n",
    "    model_frn.fit(X_train_frn, X_train_labels_frn,\n",
    "              batch_size=128,\n",
    "              epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1\n",
      "Epoch 1/5\n",
      "9540/9540 [==============================] - 3s - loss: 3.2805     \n",
      "Epoch 2/5\n",
      "9540/9540 [==============================] - 1s - loss: 3.1824     \n",
      "Epoch 3/5\n",
      "9540/9540 [==============================] - 2s - loss: 3.1709     \n",
      "Epoch 4/5\n",
      "9540/9540 [==============================] - 1s - loss: 3.1572     \n",
      "Epoch 5/5\n",
      "9540/9540 [==============================] - 2s - loss: 3.1370     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2\n",
      "Epoch 1/5\n",
      "9540/9540 [==============================] - 2s - loss: 3.1113     \n",
      "Epoch 2/5\n",
      "9540/9540 [==============================] - 2s - loss: 3.0740     \n",
      "Epoch 3/5\n",
      "9540/9540 [==============================] - 2s - loss: 3.0283     \n",
      "Epoch 4/5\n",
      "9540/9540 [==============================] - 1s - loss: 2.9702     \n",
      "Epoch 5/5\n",
      "9540/9540 [==============================] - 1s - loss: 2.8985     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 3\n",
      "Epoch 1/5\n",
      "9540/9540 [==============================] - 1s - loss: 2.8135     \n",
      "Epoch 2/5\n",
      "9540/9540 [==============================] - 1s - loss: 2.7228     \n",
      "Epoch 3/5\n",
      "9540/9540 [==============================] - 2s - loss: 2.6219     \n",
      "Epoch 4/5\n",
      "9540/9540 [==============================] - 2s - loss: 2.5248     \n",
      "Epoch 5/5\n",
      "9540/9540 [==============================] - 2s - loss: 2.4199     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 4\n",
      "Epoch 1/5\n",
      "9540/9540 [==============================] - 2s - loss: 2.3258     \n",
      "Epoch 2/5\n",
      "9540/9540 [==============================] - 2s - loss: 2.2350     \n",
      "Epoch 3/5\n",
      "9540/9540 [==============================] - 1s - loss: 2.1441     \n",
      "Epoch 4/5\n",
      "9540/9540 [==============================] - 1s - loss: 2.0640     \n",
      "Epoch 5/5\n",
      "9540/9540 [==============================] - 1s - loss: 1.9869     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 5\n",
      "Epoch 1/5\n",
      "9540/9540 [==============================] - 1s - loss: 1.9232     \n",
      "Epoch 2/5\n",
      "9540/9540 [==============================] - 1s - loss: 1.8625     \n",
      "Epoch 3/5\n",
      "9540/9540 [==============================] - 1s - loss: 1.8091     \n",
      "Epoch 4/5\n",
      "9540/9540 [==============================] - 1s - loss: 1.7589     \n",
      "Epoch 5/5\n",
      "9540/9540 [==============================] - 1s - loss: 1.7120     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 6\n",
      "Epoch 1/5\n",
      "9540/9540 [==============================] - 1s - loss: 1.6794     \n",
      "Epoch 2/5\n",
      "9540/9540 [==============================] - 1s - loss: 1.6432     \n",
      "Epoch 3/5\n",
      "9540/9540 [==============================] - 1s - loss: 1.6164     \n",
      "Epoch 4/5\n",
      "9540/9540 [==============================] - 1s - loss: 1.5889     \n",
      "Epoch 5/5\n",
      "9540/9540 [==============================] - 1s - loss: 1.5646     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 7\n",
      "Epoch 1/5\n",
      "9540/9540 [==============================] - 1s - loss: 1.5480     \n",
      "Epoch 2/5\n",
      "9540/9540 [==============================] - 1s - loss: 1.5212     \n",
      "Epoch 3/5\n",
      "9540/9540 [==============================] - 1s - loss: 1.5085     \n",
      "Epoch 4/5\n",
      "9540/9540 [==============================] - 1s - loss: 1.4919     \n",
      "Epoch 5/5\n",
      "9540/9540 [==============================] - 1s - loss: 1.4795     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 8\n",
      "Epoch 1/5\n",
      "9540/9540 [==============================] - 1s - loss: 1.4601     \n",
      "Epoch 2/5\n",
      "9540/9540 [==============================] - 1s - loss: 1.4611     \n",
      "Epoch 3/5\n",
      "9540/9540 [==============================] - 1s - loss: 1.4418     \n",
      "Epoch 4/5\n",
      "9540/9540 [==============================] - 1s - loss: 1.4324     \n",
      "Epoch 5/5\n",
      "9540/9540 [==============================] - 1s - loss: 1.4224     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 9\n",
      "Epoch 1/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.4083     \n",
      "Epoch 2/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.4085     \n",
      "Epoch 3/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.4015     \n",
      "Epoch 4/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.3884     \n",
      "Epoch 5/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.3855     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 10\n",
      "Epoch 1/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.3805     \n",
      "Epoch 2/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.3710     \n",
      "Epoch 3/5\n",
      "9540/9540 [==============================] - 1s - loss: 1.3646     \n",
      "Epoch 4/5\n",
      "9540/9540 [==============================] - 1s - loss: 1.3627     \n",
      "Epoch 5/5\n",
      "9540/9540 [==============================] - 1s - loss: 1.3556     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 11\n",
      "Epoch 1/5\n",
      "9540/9540 [==============================] - 1s - loss: 1.3472     \n",
      "Epoch 2/5\n",
      "9540/9540 [==============================] - 1s - loss: 1.3465     \n",
      "Epoch 3/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.3361     \n",
      "Epoch 4/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.3379     \n",
      "Epoch 5/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.3316     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 12\n",
      "Epoch 1/5\n",
      "9540/9540 [==============================] - 1s - loss: 1.3303     \n",
      "Epoch 2/5\n",
      "9540/9540 [==============================] - 1s - loss: 1.3283     \n",
      "Epoch 3/5\n",
      "9540/9540 [==============================] - 1s - loss: 1.3213     \n",
      "Epoch 4/5\n",
      "9540/9540 [==============================] - 1s - loss: 1.3202     \n",
      "Epoch 5/5\n",
      "9540/9540 [==============================] - 1s - loss: 1.3163     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 13\n",
      "Epoch 1/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.3121     \n",
      "Epoch 2/5\n",
      "9540/9540 [==============================] - 1s - loss: 1.3112     \n",
      "Epoch 3/5\n",
      "9540/9540 [==============================] - 1s - loss: 1.3048     \n",
      "Epoch 4/5\n",
      "9540/9540 [==============================] - 1s - loss: 1.3068     \n",
      "Epoch 5/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.2989     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 14\n",
      "Epoch 1/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.2971     \n",
      "Epoch 2/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.2963     \n",
      "Epoch 3/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.2905     \n",
      "Epoch 4/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.2894     \n",
      "Epoch 5/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.2899     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 15\n",
      "Epoch 1/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.2832     \n",
      "Epoch 2/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.2800     \n",
      "Epoch 3/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.2792     \n",
      "Epoch 4/5\n",
      "9540/9540 [==============================] - 1s - loss: 1.2807     \n",
      "Epoch 5/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.2767     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 16\n",
      "Epoch 1/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.2713     \n",
      "Epoch 2/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.2692     \n",
      "Epoch 3/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.2719     \n",
      "Epoch 4/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.2672     \n",
      "Epoch 5/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.2630     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 17\n",
      "Epoch 1/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.2627     \n",
      "Epoch 2/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.2619     \n",
      "Epoch 3/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.2536     \n",
      "Epoch 4/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.2616     \n",
      "Epoch 5/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.2566     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 18\n",
      "Epoch 1/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.2554     \n",
      "Epoch 2/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.2497     \n",
      "Epoch 3/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.2540     \n",
      "Epoch 4/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.2503     \n",
      "Epoch 5/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.2490     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 19\n",
      "Epoch 1/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.2480     \n",
      "Epoch 2/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.2452     \n",
      "Epoch 3/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.2437     \n",
      "Epoch 4/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.2439     \n",
      "Epoch 5/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.2405     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 20\n",
      "Epoch 1/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.2436     \n",
      "Epoch 2/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.2386     \n",
      "Epoch 3/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.2408     \n",
      "Epoch 4/5\n",
      "9540/9540 [==============================] - 1s - loss: 1.2375     \n",
      "Epoch 5/5\n",
      "9540/9540 [==============================] - 1s - loss: 1.2330     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 21\n",
      "Epoch 1/5\n",
      "9540/9540 [==============================] - 1s - loss: 1.2349     \n",
      "Epoch 2/5\n",
      "9540/9540 [==============================] - 1s - loss: 1.2333     \n",
      "Epoch 3/5\n",
      "9540/9540 [==============================] - 1s - loss: 1.2313     \n",
      "Epoch 4/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.2268     \n",
      "Epoch 5/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.2290     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 22\n",
      "Epoch 1/5\n",
      "9540/9540 [==============================] - 1s - loss: 1.2298     \n",
      "Epoch 2/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.2262     \n",
      "Epoch 3/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.2251     \n",
      "Epoch 4/5\n",
      "9540/9540 [==============================] - 1s - loss: 1.2239     \n",
      "Epoch 5/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.2232     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 23\n",
      "Epoch 1/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.2235     \n",
      "Epoch 2/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.2192     \n",
      "Epoch 3/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.2215     \n",
      "Epoch 4/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.2177     \n",
      "Epoch 5/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.2188     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 24\n",
      "Epoch 1/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.2197     \n",
      "Epoch 2/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.2141     \n",
      "Epoch 3/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.2148     \n",
      "Epoch 4/5\n",
      "9540/9540 [==============================] - 1s - loss: 1.2134     \n",
      "Epoch 5/5\n",
      "9540/9540 [==============================] - 1s - loss: 1.2161     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 25\n",
      "Epoch 1/5\n",
      "9540/9540 [==============================] - 1s - loss: 1.2142     \n",
      "Epoch 2/5\n",
      "9540/9540 [==============================] - 1s - loss: 1.2106     \n",
      "Epoch 3/5\n",
      "9540/9540 [==============================] - 1s - loss: 1.2122     \n",
      "Epoch 4/5\n",
      "9540/9540 [==============================] - 1s - loss: 1.2108     \n",
      "Epoch 5/5\n",
      "9540/9540 [==============================] - 1s - loss: 1.2092     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 26\n",
      "Epoch 1/5\n",
      "9540/9540 [==============================] - 1s - loss: 1.2094     \n",
      "Epoch 2/5\n",
      "9540/9540 [==============================] - 1s - loss: 1.2098     \n",
      "Epoch 3/5\n",
      "9540/9540 [==============================] - 1s - loss: 1.2037     \n",
      "Epoch 4/5\n",
      "9540/9540 [==============================] - 1s - loss: 1.2037     \n",
      "Epoch 5/5\n",
      "9540/9540 [==============================] - 1s - loss: 1.2066     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 27\n",
      "Epoch 1/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.2046     \n",
      "Epoch 2/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.2029     \n",
      "Epoch 3/5\n",
      "9540/9540 [==============================] - 1s - loss: 1.2026     \n",
      "Epoch 4/5\n",
      "9540/9540 [==============================] - 1s - loss: 1.2021     \n",
      "Epoch 5/5\n",
      "9540/9540 [==============================] - 1s - loss: 1.2003     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 28\n",
      "Epoch 1/5\n",
      "9540/9540 [==============================] - 1s - loss: 1.2030     \n",
      "Epoch 2/5\n",
      "9540/9540 [==============================] - 1s - loss: 1.2001     \n",
      "Epoch 3/5\n",
      "9540/9540 [==============================] - 1s - loss: 1.2013     \n",
      "Epoch 4/5\n",
      "9540/9540 [==============================] - 1s - loss: 1.1998     \n",
      "Epoch 5/5\n",
      "9540/9540 [==============================] - 1s - loss: 1.1999     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 29\n",
      "Epoch 1/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1964     \n",
      "Epoch 2/5\n",
      "9540/9540 [==============================] - 1s - loss: 1.1997     \n",
      "Epoch 3/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1953     \n",
      "Epoch 4/5\n",
      "9540/9540 [==============================] - 1s - loss: 1.1967     \n",
      "Epoch 5/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1928     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 30\n",
      "Epoch 1/5\n",
      "9540/9540 [==============================] - 1s - loss: 1.1950     \n",
      "Epoch 2/5\n",
      "9540/9540 [==============================] - 1s - loss: 1.1932     \n",
      "Epoch 3/5\n",
      "9540/9540 [==============================] - 1s - loss: 1.1915     \n",
      "Epoch 4/5\n",
      "9540/9540 [==============================] - 1s - loss: 1.1925     \n",
      "Epoch 5/5\n",
      "9540/9540 [==============================] - 1s - loss: 1.1932     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 31\n",
      "Epoch 1/5\n",
      "9540/9540 [==============================] - 1s - loss: 1.1913     \n",
      "Epoch 2/5\n",
      "9540/9540 [==============================] - 1s - loss: 1.1919     \n",
      "Epoch 3/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1884     \n",
      "Epoch 4/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1915     \n",
      "Epoch 5/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1886     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 32\n",
      "Epoch 1/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1869     \n",
      "Epoch 2/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1869     \n",
      "Epoch 3/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1910     \n",
      "Epoch 4/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1854     \n",
      "Epoch 5/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1829     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 33\n",
      "Epoch 1/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1867     \n",
      "Epoch 2/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1844     \n",
      "Epoch 3/5\n",
      "9540/9540 [==============================] - 1s - loss: 1.1868     \n",
      "Epoch 4/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1860     \n",
      "Epoch 5/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1837     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 34\n",
      "Epoch 1/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1852     \n",
      "Epoch 2/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1810     \n",
      "Epoch 3/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1840     \n",
      "Epoch 4/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1809     \n",
      "Epoch 5/5\n",
      "9540/9540 [==============================] - 1s - loss: 1.1816     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 35\n",
      "Epoch 1/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1778     \n",
      "Epoch 2/5\n",
      "9540/9540 [==============================] - 1s - loss: 1.1796     \n",
      "Epoch 3/5\n",
      "9540/9540 [==============================] - 1s - loss: 1.1809     \n",
      "Epoch 4/5\n",
      "9540/9540 [==============================] - 1s - loss: 1.1784     \n",
      "Epoch 5/5\n",
      "9540/9540 [==============================] - 1s - loss: 1.1792     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 36\n",
      "Epoch 1/5\n",
      "9540/9540 [==============================] - 1s - loss: 1.1784     \n",
      "Epoch 2/5\n",
      "9540/9540 [==============================] - 1s - loss: 1.1763     \n",
      "Epoch 3/5\n",
      "9540/9540 [==============================] - 1s - loss: 1.1770     \n",
      "Epoch 4/5\n",
      "9540/9540 [==============================] - 1s - loss: 1.1763     \n",
      "Epoch 5/5\n",
      "9540/9540 [==============================] - 1s - loss: 1.1767     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 37\n",
      "Epoch 1/5\n",
      "9540/9540 [==============================] - 1s - loss: 1.1771     \n",
      "Epoch 2/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1738     \n",
      "Epoch 3/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1750     \n",
      "Epoch 4/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1754     \n",
      "Epoch 5/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1769     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 38\n",
      "Epoch 1/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1697     \n",
      "Epoch 2/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1724     \n",
      "Epoch 3/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1714     \n",
      "Epoch 4/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1733     \n",
      "Epoch 5/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1722     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 39\n",
      "Epoch 1/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1684     \n",
      "Epoch 2/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1711     \n",
      "Epoch 3/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1707     \n",
      "Epoch 4/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1695     \n",
      "Epoch 5/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1687     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 40\n",
      "Epoch 1/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1687     \n",
      "Epoch 2/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1699     \n",
      "Epoch 3/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1663     \n",
      "Epoch 4/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1709     \n",
      "Epoch 5/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1677     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 41\n",
      "Epoch 1/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1678     \n",
      "Epoch 2/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1657     \n",
      "Epoch 3/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1668     \n",
      "Epoch 4/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1673     \n",
      "Epoch 5/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1679     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 42\n",
      "Epoch 1/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1645     \n",
      "Epoch 2/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1638     \n",
      "Epoch 3/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1672     \n",
      "Epoch 4/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1627     \n",
      "Epoch 5/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1691     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 43\n",
      "Epoch 1/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1635     \n",
      "Epoch 2/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1666     \n",
      "Epoch 3/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1615     \n",
      "Epoch 4/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1624     \n",
      "Epoch 5/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1615     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 44\n",
      "Epoch 1/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1618     \n",
      "Epoch 2/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1619     \n",
      "Epoch 3/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1636     \n",
      "Epoch 4/5\n",
      "9540/9540 [==============================] - 1s - loss: 1.1617     \n",
      "Epoch 5/5\n",
      "9540/9540 [==============================] - 1s - loss: 1.1611     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 45\n",
      "Epoch 1/5\n",
      "9540/9540 [==============================] - 1s - loss: 1.1630     \n",
      "Epoch 2/5\n",
      "9540/9540 [==============================] - 1s - loss: 1.1601     \n",
      "Epoch 3/5\n",
      "9540/9540 [==============================] - 1s - loss: 1.1596     \n",
      "Epoch 4/5\n",
      "9540/9540 [==============================] - 1s - loss: 1.1591     \n",
      "Epoch 5/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1589     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 46\n",
      "Epoch 1/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1619     \n",
      "Epoch 2/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1609     \n",
      "Epoch 3/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1570     \n",
      "Epoch 4/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1617     \n",
      "Epoch 5/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1570     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 47\n",
      "Epoch 1/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1569     \n",
      "Epoch 2/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1582     \n",
      "Epoch 3/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1556     \n",
      "Epoch 4/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1559     \n",
      "Epoch 5/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1570     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 48\n",
      "Epoch 1/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1524     \n",
      "Epoch 2/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1556     \n",
      "Epoch 3/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1559     \n",
      "Epoch 4/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1571     \n",
      "Epoch 5/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1547     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 49\n",
      "Epoch 1/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1564     \n",
      "Epoch 2/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1548     \n",
      "Epoch 3/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1569     \n",
      "Epoch 4/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1531     \n",
      "Epoch 5/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1529     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 50\n",
      "Epoch 1/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1544     \n",
      "Epoch 2/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1534     \n",
      "Epoch 3/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1519     \n",
      "Epoch 4/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1558     \n",
      "Epoch 5/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1525     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 51\n",
      "Epoch 1/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1549     \n",
      "Epoch 2/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1520     \n",
      "Epoch 3/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1516     \n",
      "Epoch 4/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1504     \n",
      "Epoch 5/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1524     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 52\n",
      "Epoch 1/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1519     \n",
      "Epoch 2/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1534     \n",
      "Epoch 3/5\n",
      "9540/9540 [==============================] - 1s - loss: 1.1490     \n",
      "Epoch 4/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1507     \n",
      "Epoch 5/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1500     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 53\n",
      "Epoch 1/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1490     \n",
      "Epoch 2/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1514     \n",
      "Epoch 3/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1502     \n",
      "Epoch 4/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1529     \n",
      "Epoch 5/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1478     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 54\n",
      "Epoch 1/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1518     \n",
      "Epoch 2/5\n",
      "9540/9540 [==============================] - 1s - loss: 1.1500     \n",
      "Epoch 3/5\n",
      "9540/9540 [==============================] - 1s - loss: 1.1491     \n",
      "Epoch 4/5\n",
      "9540/9540 [==============================] - 1s - loss: 1.1478     \n",
      "Epoch 5/5\n",
      "9540/9540 [==============================] - 1s - loss: 1.1473     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 55\n",
      "Epoch 1/5\n",
      "9540/9540 [==============================] - 1s - loss: 1.1472     \n",
      "Epoch 2/5\n",
      "9540/9540 [==============================] - 1s - loss: 1.1498     \n",
      "Epoch 3/5\n",
      "9540/9540 [==============================] - 1s - loss: 1.1494     \n",
      "Epoch 4/5\n",
      "9540/9540 [==============================] - 1s - loss: 1.1455     \n",
      "Epoch 5/5\n",
      "9540/9540 [==============================] - 1s - loss: 1.1442     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 56\n",
      "Epoch 1/5\n",
      "9540/9540 [==============================] - 1s - loss: 1.1483     \n",
      "Epoch 2/5\n",
      "9540/9540 [==============================] - 1s - loss: 1.1472     \n",
      "Epoch 3/5\n",
      "9540/9540 [==============================] - 1s - loss: 1.1467     \n",
      "Epoch 4/5\n",
      "9540/9540 [==============================] - 1s - loss: 1.1439     \n",
      "Epoch 5/5\n",
      "9540/9540 [==============================] - 1s - loss: 1.1458     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 57\n",
      "Epoch 1/5\n",
      "9540/9540 [==============================] - 1s - loss: 1.1465     \n",
      "Epoch 2/5\n",
      "9540/9540 [==============================] - 1s - loss: 1.1433     \n",
      "Epoch 3/5\n",
      "9540/9540 [==============================] - 1s - loss: 1.1446     \n",
      "Epoch 4/5\n",
      "9540/9540 [==============================] - 1s - loss: 1.1471     \n",
      "Epoch 5/5\n",
      "9540/9540 [==============================] - 1s - loss: 1.1423     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 58\n",
      "Epoch 1/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1466     \n",
      "Epoch 2/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1477     \n",
      "Epoch 3/5\n",
      "9540/9540 [==============================] - 1s - loss: 1.1440     \n",
      "Epoch 4/5\n",
      "9540/9540 [==============================] - 1s - loss: 1.1412     \n",
      "Epoch 5/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1425     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 59\n",
      "Epoch 1/5\n",
      "9540/9540 [==============================] - 1s - loss: 1.1427     \n",
      "Epoch 2/5\n",
      "9540/9540 [==============================] - 1s - loss: 1.1426     \n",
      "Epoch 3/5\n",
      "9540/9540 [==============================] - 1s - loss: 1.1424     \n",
      "Epoch 4/5\n",
      "9540/9540 [==============================] - 1s - loss: 1.1424     \n",
      "Epoch 5/5\n",
      "9540/9540 [==============================] - 1s - loss: 1.1396     \n"
     ]
    }
   ],
   "source": [
    "# train the Russian model\n",
    "for iteration in range(1, 60): # Make this 26\n",
    "    print()\n",
    "    print('-' * 50)\n",
    "    print('Iteration', iteration)\n",
    "    model_rus.fit(X_train_rus, X_train_labels_rus,\n",
    "              batch_size=128,\n",
    "              epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1\n",
      "Epoch 1/5\n",
      "9658/9658 [==============================] - 2s - loss: 3.0703     \n",
      "Epoch 2/5\n",
      "9658/9658 [==============================] - 1s - loss: 2.9751     \n",
      "Epoch 3/5\n",
      "9658/9658 [==============================] - 1s - loss: 2.9689     \n",
      "Epoch 4/5\n",
      "9658/9658 [==============================] - 1s - loss: 2.9555     \n",
      "Epoch 5/5\n",
      "9658/9658 [==============================] - 2s - loss: 2.9433     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2\n",
      "Epoch 1/5\n",
      "9658/9658 [==============================] - 1s - loss: 2.9280     \n",
      "Epoch 2/5\n",
      "9658/9658 [==============================] - 1s - loss: 2.9068     \n",
      "Epoch 3/5\n",
      "9658/9658 [==============================] - 3s - loss: 2.8802     \n",
      "Epoch 4/5\n",
      "9658/9658 [==============================] - 2s - loss: 2.8437     \n",
      "Epoch 5/5\n",
      "9658/9658 [==============================] - 2s - loss: 2.7948     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 3\n",
      "Epoch 1/5\n",
      "9658/9658 [==============================] - 2s - loss: 2.7349     \n",
      "Epoch 2/5\n",
      "9658/9658 [==============================] - 2s - loss: 2.6672     \n",
      "Epoch 3/5\n",
      "9658/9658 [==============================] - 2s - loss: 2.5955     \n",
      "Epoch 4/5\n",
      "9658/9658 [==============================] - 2s - loss: 2.5141     \n",
      "Epoch 5/5\n",
      "9658/9658 [==============================] - 2s - loss: 2.4362     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 4\n",
      "Epoch 1/5\n",
      "9658/9658 [==============================] - 2s - loss: 2.3578     \n",
      "Epoch 2/5\n",
      "9658/9658 [==============================] - 2s - loss: 2.2909     \n",
      "Epoch 3/5\n",
      "9658/9658 [==============================] - 2s - loss: 2.2139     \n",
      "Epoch 4/5\n",
      "9658/9658 [==============================] - 2s - loss: 2.1450     \n",
      "Epoch 5/5\n",
      "9658/9658 [==============================] - 2s - loss: 2.0849     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 5\n",
      "Epoch 1/5\n",
      "9658/9658 [==============================] - 2s - loss: 2.0280     \n",
      "Epoch 2/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.9723     \n",
      "Epoch 3/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.9225     \n",
      "Epoch 4/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.8846     \n",
      "Epoch 5/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.8363     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 6\n",
      "Epoch 1/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.8022     \n",
      "Epoch 2/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.7688     \n",
      "Epoch 3/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.7365     \n",
      "Epoch 4/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.7062     \n",
      "Epoch 5/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.6893     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 7\n",
      "Epoch 1/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.6631     \n",
      "Epoch 2/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.6429     \n",
      "Epoch 3/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.6254     \n",
      "Epoch 4/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.6065     \n",
      "Epoch 5/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.5980     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 8\n",
      "Epoch 1/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.5859     \n",
      "Epoch 2/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.5687     \n",
      "Epoch 3/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.5569     \n",
      "Epoch 4/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.5488     \n",
      "Epoch 5/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.5357     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 9\n",
      "Epoch 1/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.5314     \n",
      "Epoch 2/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.5181     \n",
      "Epoch 3/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.5103     \n",
      "Epoch 4/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.5040     \n",
      "Epoch 5/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.5001     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 10\n",
      "Epoch 1/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.4927     \n",
      "Epoch 2/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.4869     \n",
      "Epoch 3/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.4826     \n",
      "Epoch 4/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.4735     \n",
      "Epoch 5/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.4677     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 11\n",
      "Epoch 1/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.4635     \n",
      "Epoch 2/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.4632     \n",
      "Epoch 3/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.4517     \n",
      "Epoch 4/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.4520     \n",
      "Epoch 5/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.4483     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 12\n",
      "Epoch 1/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.4396     \n",
      "Epoch 2/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.4396     \n",
      "Epoch 3/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.4370     \n",
      "Epoch 4/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.4321     \n",
      "Epoch 5/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.4283     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 13\n",
      "Epoch 1/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.4267     \n",
      "Epoch 2/5\n",
      "9658/9658 [==============================] - 3s - loss: 1.4243     \n",
      "Epoch 3/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.4240     \n",
      "Epoch 4/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.4143     \n",
      "Epoch 5/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.4101     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 14\n",
      "Epoch 1/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.4143     \n",
      "Epoch 2/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.4088     \n",
      "Epoch 3/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.4058     \n",
      "Epoch 4/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.4033     \n",
      "Epoch 5/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.3994     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 15\n",
      "Epoch 1/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.3963     \n",
      "Epoch 2/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.3967     \n",
      "Epoch 3/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.3929     \n",
      "Epoch 4/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.3955     \n",
      "Epoch 5/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.3888     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 16\n",
      "Epoch 1/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.3873     \n",
      "Epoch 2/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.3848     \n",
      "Epoch 3/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.3817     \n",
      "Epoch 4/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.3811     \n",
      "Epoch 5/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.3823     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 17\n",
      "Epoch 1/5\n",
      "9658/9658 [==============================] - 1s - loss: 1.3800     \n",
      "Epoch 2/5\n",
      "9658/9658 [==============================] - 1s - loss: 1.3784     \n",
      "Epoch 3/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.3752     \n",
      "Epoch 4/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.3700     \n",
      "Epoch 5/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.3710     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 18\n",
      "Epoch 1/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.3667     \n",
      "Epoch 2/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.3686     \n",
      "Epoch 3/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.3678     \n",
      "Epoch 4/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.3644     \n",
      "Epoch 5/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.3614     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 19\n",
      "Epoch 1/5\n",
      "9658/9658 [==============================] - 1s - loss: 1.3624     \n",
      "Epoch 2/5\n",
      "9658/9658 [==============================] - 1s - loss: 1.3657     \n",
      "Epoch 3/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.3583     \n",
      "Epoch 4/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.3590     \n",
      "Epoch 5/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.3577     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 20\n",
      "Epoch 1/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.3556     \n",
      "Epoch 2/5\n",
      "9658/9658 [==============================] - 1s - loss: 1.3550     \n",
      "Epoch 3/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.3565     \n",
      "Epoch 4/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.3532     \n",
      "Epoch 5/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.3517     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 21\n",
      "Epoch 1/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.3540     \n",
      "Epoch 2/5\n",
      "9658/9658 [==============================] - 3s - loss: 1.3493     \n",
      "Epoch 3/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.3482     \n",
      "Epoch 4/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.3486     \n",
      "Epoch 5/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.3443     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 22\n",
      "Epoch 1/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.3478     \n",
      "Epoch 2/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.3440     \n",
      "Epoch 3/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.3457     \n",
      "Epoch 4/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.3442     \n",
      "Epoch 5/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.3397     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 23\n",
      "Epoch 1/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.3351     \n",
      "Epoch 2/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.3396     \n",
      "Epoch 3/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.3396     \n",
      "Epoch 4/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.3362     \n",
      "Epoch 5/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.3379     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 24\n",
      "Epoch 1/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.3350     \n",
      "Epoch 2/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.3358     \n",
      "Epoch 3/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.3352     \n",
      "Epoch 4/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.3303     \n",
      "Epoch 5/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.3335     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 25\n",
      "Epoch 1/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.3313     \n",
      "Epoch 2/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.3300     \n",
      "Epoch 3/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.3301     \n",
      "Epoch 4/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.3307     \n",
      "Epoch 5/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.3303     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 26\n",
      "Epoch 1/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.3282     \n",
      "Epoch 2/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.3250     \n",
      "Epoch 3/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.3262     \n",
      "Epoch 4/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.3237     \n",
      "Epoch 5/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.3212     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 27\n",
      "Epoch 1/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.3232     \n",
      "Epoch 2/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.3253     \n",
      "Epoch 3/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.3200     \n",
      "Epoch 4/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.3215     \n",
      "Epoch 5/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.3217     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 28\n",
      "Epoch 1/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.3186     \n",
      "Epoch 2/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.3188     \n",
      "Epoch 3/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.3177     \n",
      "Epoch 4/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.3185     \n",
      "Epoch 5/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.3147     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 29\n",
      "Epoch 1/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.3174     \n",
      "Epoch 2/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.3175     \n",
      "Epoch 3/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.3153     \n",
      "Epoch 4/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.3118     \n",
      "Epoch 5/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.3169     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 30\n",
      "Epoch 1/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.3159     \n",
      "Epoch 2/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.3125     \n",
      "Epoch 3/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.3122     \n",
      "Epoch 4/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.3118     \n",
      "Epoch 5/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.3103     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 31\n",
      "Epoch 1/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.3104     \n",
      "Epoch 2/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.3103     \n",
      "Epoch 3/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.3095     \n",
      "Epoch 4/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.3111     \n",
      "Epoch 5/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.3071     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 32\n",
      "Epoch 1/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.3067     \n",
      "Epoch 2/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.3062     \n",
      "Epoch 3/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.3080     \n",
      "Epoch 4/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.3075     \n",
      "Epoch 5/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.3056     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 33\n",
      "Epoch 1/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.3051     \n",
      "Epoch 2/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.3088     \n",
      "Epoch 3/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.3045     \n",
      "Epoch 4/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.3052     \n",
      "Epoch 5/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.3029     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 34\n",
      "Epoch 1/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.3042     \n",
      "Epoch 2/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.3025     \n",
      "Epoch 3/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.2987     \n",
      "Epoch 4/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.3031     \n",
      "Epoch 5/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.3004     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 35\n",
      "Epoch 1/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.3012     \n",
      "Epoch 2/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.2968     \n",
      "Epoch 3/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.3002     \n",
      "Epoch 4/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.3005     \n",
      "Epoch 5/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.2952     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 36\n",
      "Epoch 1/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.3018     \n",
      "Epoch 2/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.2980     \n",
      "Epoch 3/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.2974     \n",
      "Epoch 4/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.2952     \n",
      "Epoch 5/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.2960     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 37\n",
      "Epoch 1/5\n",
      "9658/9658 [==============================] - 3s - loss: 1.2974     \n",
      "Epoch 2/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.2952     \n",
      "Epoch 3/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.2972     \n",
      "Epoch 4/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.2964     \n",
      "Epoch 5/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.2968     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 38\n",
      "Epoch 1/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.2928     \n",
      "Epoch 2/5\n",
      "9658/9658 [==============================] - 1s - loss: 1.2903     \n",
      "Epoch 3/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.2936     \n",
      "Epoch 4/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.2951     \n",
      "Epoch 5/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.2946     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 39\n",
      "Epoch 1/5\n",
      "9658/9658 [==============================] - 1s - loss: 1.2927     \n",
      "Epoch 2/5\n",
      "9658/9658 [==============================] - 1s - loss: 1.2914     \n",
      "Epoch 3/5\n",
      "9658/9658 [==============================] - 1s - loss: 1.2898     \n",
      "Epoch 4/5\n",
      "9658/9658 [==============================] - 1s - loss: 1.2928     \n",
      "Epoch 5/5\n",
      "9658/9658 [==============================] - 1s - loss: 1.2887     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 40\n",
      "Epoch 1/5\n",
      "9658/9658 [==============================] - 1s - loss: 1.2897     \n",
      "Epoch 2/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.2942     \n",
      "Epoch 3/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.2869     \n",
      "Epoch 4/5\n",
      "9658/9658 [==============================] - 1s - loss: 1.2901     \n",
      "Epoch 5/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.2887     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 41\n",
      "Epoch 1/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.2877     \n",
      "Epoch 2/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.2911     \n",
      "Epoch 3/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.2839     \n",
      "Epoch 4/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.2863     \n",
      "Epoch 5/5\n",
      "9658/9658 [==============================] - 1s - loss: 1.2883     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 42\n",
      "Epoch 1/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.2850     \n",
      "Epoch 2/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.2873     \n",
      "Epoch 3/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.2855     \n",
      "Epoch 4/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.2853     \n",
      "Epoch 5/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.2867     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 43\n",
      "Epoch 1/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.2867     \n",
      "Epoch 2/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.2845     \n",
      "Epoch 3/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.2845     \n",
      "Epoch 4/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.2841     \n",
      "Epoch 5/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.2846     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 44\n",
      "Epoch 1/5\n",
      "9658/9658 [==============================] - 1s - loss: 1.2858     \n",
      "Epoch 2/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.2843     \n",
      "Epoch 3/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.2830     \n",
      "Epoch 4/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.2817     \n",
      "Epoch 5/5\n",
      "9658/9658 [==============================] - 1s - loss: 1.2826     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 45\n",
      "Epoch 1/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.2826     \n",
      "Epoch 2/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.2850     \n",
      "Epoch 3/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.2809     \n",
      "Epoch 4/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.2805     \n",
      "Epoch 5/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.2800     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 46\n",
      "Epoch 1/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.2827     \n",
      "Epoch 2/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.2797     \n",
      "Epoch 3/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.2787     \n",
      "Epoch 4/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.2801     \n",
      "Epoch 5/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.2797     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 47\n",
      "Epoch 1/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.2773     \n",
      "Epoch 2/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.2802     \n",
      "Epoch 3/5\n",
      "9658/9658 [==============================] - 1s - loss: 1.2775     \n",
      "Epoch 4/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.2787     \n",
      "Epoch 5/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.2810     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 48\n",
      "Epoch 1/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.2760     \n",
      "Epoch 2/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.2762     \n",
      "Epoch 3/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.2760     \n",
      "Epoch 4/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.2780     \n",
      "Epoch 5/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.2759     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 49\n",
      "Epoch 1/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.2770     \n",
      "Epoch 2/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.2733     \n",
      "Epoch 3/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.2771     \n",
      "Epoch 4/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.2777     \n",
      "Epoch 5/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.2738     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 50\n",
      "Epoch 1/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.2729     \n",
      "Epoch 2/5\n",
      "9658/9658 [==============================] - 1s - loss: 1.2754     \n",
      "Epoch 3/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.2748     \n",
      "Epoch 4/5\n",
      "9658/9658 [==============================] - 1s - loss: 1.2734     \n",
      "Epoch 5/5\n",
      "9658/9658 [==============================] - 1s - loss: 1.2735     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 51\n",
      "Epoch 1/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.2754     \n",
      "Epoch 2/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.2745     \n",
      "Epoch 3/5\n",
      "9658/9658 [==============================] - 1s - loss: 1.2681     \n",
      "Epoch 4/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.2759     \n",
      "Epoch 5/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.2716     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 52\n",
      "Epoch 1/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.2732     \n",
      "Epoch 2/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.2700     \n",
      "Epoch 3/5\n",
      "9658/9658 [==============================] - 1s - loss: 1.2704     \n",
      "Epoch 4/5\n",
      "9658/9658 [==============================] - 1s - loss: 1.2720     \n",
      "Epoch 5/5\n",
      "9658/9658 [==============================] - 1s - loss: 1.2718     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 53\n",
      "Epoch 1/5\n",
      "9658/9658 [==============================] - 1s - loss: 1.2716     \n",
      "Epoch 2/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.2706     \n",
      "Epoch 3/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.2746     \n",
      "Epoch 4/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.2718     \n",
      "Epoch 5/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.2686     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 54\n",
      "Epoch 1/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.2700     \n",
      "Epoch 2/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.2704     \n",
      "Epoch 3/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.2729     \n",
      "Epoch 4/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.2666     \n",
      "Epoch 5/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.2711     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 55\n",
      "Epoch 1/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.2712     \n",
      "Epoch 2/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.2682     \n",
      "Epoch 3/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.2676     \n",
      "Epoch 4/5\n",
      "9658/9658 [==============================] - 1s - loss: 1.2709     \n",
      "Epoch 5/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.2680     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 56\n",
      "Epoch 1/5\n",
      "9658/9658 [==============================] - 1s - loss: 1.2713     \n",
      "Epoch 2/5\n",
      "9658/9658 [==============================] - 1s - loss: 1.2574     \n",
      "Epoch 3/5\n",
      "9658/9658 [==============================] - 1s - loss: 1.2686     \n",
      "Epoch 4/5\n",
      "9658/9658 [==============================] - 1s - loss: 1.2671     \n",
      "Epoch 5/5\n",
      "9658/9658 [==============================] - 1s - loss: 1.2646     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 57\n",
      "Epoch 1/5\n",
      "9658/9658 [==============================] - 1s - loss: 1.2666     \n",
      "Epoch 2/5\n",
      "9658/9658 [==============================] - 1s - loss: 1.2665     \n",
      "Epoch 3/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.2661     \n",
      "Epoch 4/5\n",
      "9658/9658 [==============================] - 1s - loss: 1.2661     \n",
      "Epoch 5/5\n",
      "9658/9658 [==============================] - 1s - loss: 1.2634     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 58\n",
      "Epoch 1/5\n",
      "9658/9658 [==============================] - 1s - loss: 1.2651     \n",
      "Epoch 2/5\n",
      "9658/9658 [==============================] - 1s - loss: 1.2656     \n",
      "Epoch 3/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.2660     \n",
      "Epoch 4/5\n",
      "9658/9658 [==============================] - 1s - loss: 1.2670     \n",
      "Epoch 5/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.2646     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 59\n",
      "Epoch 1/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.2675     \n",
      "Epoch 2/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.2645     \n",
      "Epoch 3/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.2658     \n",
      "Epoch 4/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.2642     \n",
      "Epoch 5/5\n",
      "9658/9658 [==============================] - 2s - loss: 1.2666     \n"
     ]
    }
   ],
   "source": [
    "# train the German model\n",
    "for iteration in range(1, 60): # Make this 26\n",
    "    print()\n",
    "    print('-' * 50)\n",
    "    print('Iteration', iteration)\n",
    "    model_ger.fit(X_train_ger, X_train_labels_ger,\n",
    "              batch_size=128,\n",
    "              epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1\n",
      "Epoch 1/5\n",
      "10033/10033 [==============================] - 3s - loss: 3.2737     \n",
      "Epoch 2/5\n",
      "10033/10033 [==============================] - 2s - loss: 3.1853     \n",
      "Epoch 3/5\n",
      "10033/10033 [==============================] - 2s - loss: 3.1763     \n",
      "Epoch 4/5\n",
      "10033/10033 [==============================] - 2s - loss: 3.1631     \n",
      "Epoch 5/5\n",
      "10033/10033 [==============================] - 2s - loss: 3.1420     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2\n",
      "Epoch 1/5\n",
      "10033/10033 [==============================] - 2s - loss: 3.1118     \n",
      "Epoch 2/5\n",
      "10033/10033 [==============================] - 1s - loss: 3.0696     \n",
      "Epoch 3/5\n",
      "10033/10033 [==============================] - 1s - loss: 3.0141     \n",
      "Epoch 4/5\n",
      "10033/10033 [==============================] - 1s - loss: 2.9429     \n",
      "Epoch 5/5\n",
      "10033/10033 [==============================] - 1s - loss: 2.8600     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 3\n",
      "Epoch 1/5\n",
      "10033/10033 [==============================] - 2s - loss: 2.7674     \n",
      "Epoch 2/5\n",
      "10033/10033 [==============================] - 2s - loss: 2.6634     \n",
      "Epoch 3/5\n",
      "10033/10033 [==============================] - 2s - loss: 2.5615     \n",
      "Epoch 4/5\n",
      "10033/10033 [==============================] - 2s - loss: 2.4616     \n",
      "Epoch 5/5\n",
      "10033/10033 [==============================] - 2s - loss: 2.3583     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 4\n",
      "Epoch 1/5\n",
      "10033/10033 [==============================] - 2s - loss: 2.2661     \n",
      "Epoch 2/5\n",
      "10033/10033 [==============================] - 2s - loss: 2.1723     \n",
      "Epoch 3/5\n",
      "10033/10033 [==============================] - 1s - loss: 2.0964     \n",
      "Epoch 4/5\n",
      "10033/10033 [==============================] - 1s - loss: 2.0238     \n",
      "Epoch 5/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.9463     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 5\n",
      "Epoch 1/5\n",
      "10033/10033 [==============================] - 3s - loss: 1.8927     \n",
      "Epoch 2/5\n",
      "10033/10033 [==============================] - 3s - loss: 1.8465     \n",
      "Epoch 3/5\n",
      "10033/10033 [==============================] - 3s - loss: 1.7960     \n",
      "Epoch 4/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.7561     \n",
      "Epoch 5/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.7145     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 6\n",
      "Epoch 1/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.6869     \n",
      "Epoch 2/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.6597     \n",
      "Epoch 3/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.6375     \n",
      "Epoch 4/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.6153     \n",
      "Epoch 5/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.5962     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 7\n",
      "Epoch 1/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.5789     \n",
      "Epoch 2/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.5538     \n",
      "Epoch 3/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.5485     \n",
      "Epoch 4/5\n",
      "10033/10033 [==============================] - 3s - loss: 1.5253     \n",
      "Epoch 5/5\n",
      "10033/10033 [==============================] - 3s - loss: 1.5165     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 8\n",
      "Epoch 1/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.5059     \n",
      "Epoch 2/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.4967     \n",
      "Epoch 3/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.4861     \n",
      "Epoch 4/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.4752     \n",
      "Epoch 5/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.4618     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 9\n",
      "Epoch 1/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.4553     \n",
      "Epoch 2/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.4492     \n",
      "Epoch 3/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.4437     \n",
      "Epoch 4/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.4382     \n",
      "Epoch 5/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.4297     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 10\n",
      "Epoch 1/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.4270     \n",
      "Epoch 2/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.4167     \n",
      "Epoch 3/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.4135     \n",
      "Epoch 4/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.4101     \n",
      "Epoch 5/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.4013     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 11\n",
      "Epoch 1/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.3964     \n",
      "Epoch 2/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.3912     \n",
      "Epoch 3/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.3846     \n",
      "Epoch 4/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.3807     \n",
      "Epoch 5/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.3773     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 12\n",
      "Epoch 1/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.3717     \n",
      "Epoch 2/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.3699     \n",
      "Epoch 3/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.3657     \n",
      "Epoch 4/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.3639     \n",
      "Epoch 5/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.3605     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 13\n",
      "Epoch 1/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.3559     \n",
      "Epoch 2/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.3511     \n",
      "Epoch 3/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.3491     \n",
      "Epoch 4/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.3450     \n",
      "Epoch 5/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.3451     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 14\n",
      "Epoch 1/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.3409     \n",
      "Epoch 2/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.3390     \n",
      "Epoch 3/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.3377     \n",
      "Epoch 4/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.3325     \n",
      "Epoch 5/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.3272     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 15\n",
      "Epoch 1/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.3299     \n",
      "Epoch 2/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.3248     \n",
      "Epoch 3/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.3235     \n",
      "Epoch 4/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.3229     \n",
      "Epoch 5/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.3184     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 16\n",
      "Epoch 1/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.3202     \n",
      "Epoch 2/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.3156     \n",
      "Epoch 3/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.3127     \n",
      "Epoch 4/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.3146     \n",
      "Epoch 5/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.3130     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 17\n",
      "Epoch 1/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.3053     \n",
      "Epoch 2/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.3043     \n",
      "Epoch 3/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.3063     \n",
      "Epoch 4/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.3028     \n",
      "Epoch 5/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.3017     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 18\n",
      "Epoch 1/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.2966     \n",
      "Epoch 2/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.2989     \n",
      "Epoch 3/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.2948     \n",
      "Epoch 4/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.2936     \n",
      "Epoch 5/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.2917     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 19\n",
      "Epoch 1/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.2905     \n",
      "Epoch 2/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.2911     \n",
      "Epoch 3/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.2883     \n",
      "Epoch 4/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.2897     \n",
      "Epoch 5/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.2850     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 20\n",
      "Epoch 1/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.2818     \n",
      "Epoch 2/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.2887     \n",
      "Epoch 3/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.2840     \n",
      "Epoch 4/5\n",
      "10033/10033 [==============================] - 1s - loss: 1.2798     \n",
      "Epoch 5/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.2800     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 21\n",
      "Epoch 1/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.2783     \n",
      "Epoch 2/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.2744     \n",
      "Epoch 3/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.2761     \n",
      "Epoch 4/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.2744     \n",
      "Epoch 5/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.2724     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 22\n",
      "Epoch 1/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.2721     \n",
      "Epoch 2/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.2691     \n",
      "Epoch 3/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.2679     \n",
      "Epoch 4/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.2698     \n",
      "Epoch 5/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.2703     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 23\n",
      "Epoch 1/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.2657     \n",
      "Epoch 2/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.2687     \n",
      "Epoch 3/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.2696     \n",
      "Epoch 4/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.2638     \n",
      "Epoch 5/5\n",
      "10033/10033 [==============================] - 3s - loss: 1.2635     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 24\n",
      "Epoch 1/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.2615     \n",
      "Epoch 2/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.2588     \n",
      "Epoch 3/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.2587     \n",
      "Epoch 4/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.2582     \n",
      "Epoch 5/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.2561     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 25\n",
      "Epoch 1/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.2560     \n",
      "Epoch 2/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.2554     \n",
      "Epoch 3/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.2526     \n",
      "Epoch 4/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.2546     \n",
      "Epoch 5/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.2549     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 26\n",
      "Epoch 1/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.2505     \n",
      "Epoch 2/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.2524     \n",
      "Epoch 3/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.2528     \n",
      "Epoch 4/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.2491     \n",
      "Epoch 5/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.2498     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 27\n",
      "Epoch 1/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.2491     \n",
      "Epoch 2/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.2442     \n",
      "Epoch 3/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.2460     \n",
      "Epoch 4/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.2451     \n",
      "Epoch 5/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.2472     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 28\n",
      "Epoch 1/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.2476     \n",
      "Epoch 2/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.2427     \n",
      "Epoch 3/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.2429     \n",
      "Epoch 4/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.2444     \n",
      "Epoch 5/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.2409     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 29\n",
      "Epoch 1/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.2409     \n",
      "Epoch 2/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.2398     \n",
      "Epoch 3/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.2390     \n",
      "Epoch 4/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.2356     \n",
      "Epoch 5/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.2388     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 30\n",
      "Epoch 1/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.2344     \n",
      "Epoch 2/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.2405     \n",
      "Epoch 3/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.2358     \n",
      "Epoch 4/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.2378     \n",
      "Epoch 5/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.2349     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 31\n",
      "Epoch 1/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.2356     \n",
      "Epoch 2/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.2329     \n",
      "Epoch 3/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.2341     \n",
      "Epoch 4/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.2332     \n",
      "Epoch 5/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.2337     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 32\n",
      "Epoch 1/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.2308     \n",
      "Epoch 2/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.2342     \n",
      "Epoch 3/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.2317     \n",
      "Epoch 4/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.2323     \n",
      "Epoch 5/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.2276     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 33\n",
      "Epoch 1/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.2306     \n",
      "Epoch 2/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.2283     \n",
      "Epoch 3/5\n",
      "10033/10033 [==============================] - 3s - loss: 1.2277     \n",
      "Epoch 4/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.2265     \n",
      "Epoch 5/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.2251     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 34\n",
      "Epoch 1/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.2286     \n",
      "Epoch 2/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.2247     \n",
      "Epoch 3/5\n",
      "10033/10033 [==============================] - 1s - loss: 1.2274     \n",
      "Epoch 4/5\n",
      "10033/10033 [==============================] - 1s - loss: 1.2254     \n",
      "Epoch 5/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.2239     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 35\n",
      "Epoch 1/5\n",
      "10033/10033 [==============================] - 1s - loss: 1.2211     \n",
      "Epoch 2/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.2256     \n",
      "Epoch 3/5\n",
      "10033/10033 [==============================] - 1s - loss: 1.2213     \n",
      "Epoch 4/5\n",
      "10033/10033 [==============================] - 1s - loss: 1.2220     \n",
      "Epoch 5/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.2216     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 36\n",
      "Epoch 1/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.2201     \n",
      "Epoch 2/5\n",
      "10033/10033 [==============================] - 1s - loss: 1.2199     \n",
      "Epoch 3/5\n",
      "10033/10033 [==============================] - 1s - loss: 1.2222     \n",
      "Epoch 4/5\n",
      "10033/10033 [==============================] - 1s - loss: 1.2194     \n",
      "Epoch 5/5\n",
      "10033/10033 [==============================] - 1s - loss: 1.2190     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 37\n",
      "Epoch 1/5\n",
      "10033/10033 [==============================] - 1s - loss: 1.2191     \n",
      "Epoch 2/5\n",
      "10033/10033 [==============================] - 1s - loss: 1.2194     \n",
      "Epoch 3/5\n",
      "10033/10033 [==============================] - 1s - loss: 1.2164     \n",
      "Epoch 4/5\n",
      "10033/10033 [==============================] - 1s - loss: 1.2171     \n",
      "Epoch 5/5\n",
      "10033/10033 [==============================] - 1s - loss: 1.2165     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 38\n",
      "Epoch 1/5\n",
      "10033/10033 [==============================] - 1s - loss: 1.2172     \n",
      "Epoch 2/5\n",
      "10033/10033 [==============================] - 1s - loss: 1.2181     \n",
      "Epoch 3/5\n",
      "10033/10033 [==============================] - 1s - loss: 1.2166     \n",
      "Epoch 4/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.2143     \n",
      "Epoch 5/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.2167     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 39\n",
      "Epoch 1/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.2129     \n",
      "Epoch 2/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.2145     \n",
      "Epoch 3/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.2138     \n",
      "Epoch 4/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.2162     \n",
      "Epoch 5/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.2134     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 40\n",
      "Epoch 1/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.2130     \n",
      "Epoch 2/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.2143     \n",
      "Epoch 3/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.2104     \n",
      "Epoch 4/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.2131     \n",
      "Epoch 5/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.2106     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 41\n",
      "Epoch 1/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.2131     \n",
      "Epoch 2/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.2098     \n",
      "Epoch 3/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.2079     \n",
      "Epoch 4/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.2090     \n",
      "Epoch 5/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.2071     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 42\n",
      "Epoch 1/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.2091     \n",
      "Epoch 2/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.2075     \n",
      "Epoch 3/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.2075     \n",
      "Epoch 4/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.2093     \n",
      "Epoch 5/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.2079     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 43\n",
      "Epoch 1/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.2077     \n",
      "Epoch 2/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.2081     \n",
      "Epoch 3/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.2053     \n",
      "Epoch 4/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.2069     \n",
      "Epoch 5/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.2071     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 44\n",
      "Epoch 1/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.2053     \n",
      "Epoch 2/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.2017     \n",
      "Epoch 3/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.2037     \n",
      "Epoch 4/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.2019     \n",
      "Epoch 5/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.2043     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 45\n",
      "Epoch 1/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.2038     \n",
      "Epoch 2/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.2032     \n",
      "Epoch 3/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.2024     \n",
      "Epoch 4/5\n",
      "10033/10033 [==============================] - 1s - loss: 1.2025     \n",
      "Epoch 5/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.2043     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 46\n",
      "Epoch 1/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.2011     \n",
      "Epoch 2/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.2014     \n",
      "Epoch 3/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.2014     \n",
      "Epoch 4/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.2011     \n",
      "Epoch 5/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.1992     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 47\n",
      "Epoch 1/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.1996     \n",
      "Epoch 2/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.2003     \n",
      "Epoch 3/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.1974     \n",
      "Epoch 4/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.1998     \n",
      "Epoch 5/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.1954     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 48\n",
      "Epoch 1/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.2022     \n",
      "Epoch 2/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.1997     \n",
      "Epoch 3/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.1948     \n",
      "Epoch 4/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.1978     \n",
      "Epoch 5/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.1993     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 49\n",
      "Epoch 1/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.1973     \n",
      "Epoch 2/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.1986     \n",
      "Epoch 3/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.1978     \n",
      "Epoch 4/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.2006     \n",
      "Epoch 5/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.1951     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 50\n",
      "Epoch 1/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.1967     \n",
      "Epoch 2/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.1969     \n",
      "Epoch 3/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.1921     \n",
      "Epoch 4/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.1985     \n",
      "Epoch 5/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.1958     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 51\n",
      "Epoch 1/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.1933     \n",
      "Epoch 2/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.1954     \n",
      "Epoch 3/5\n",
      "10033/10033 [==============================] - 1s - loss: 1.1971     \n",
      "Epoch 4/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.1945     \n",
      "Epoch 5/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.1940     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 52\n",
      "Epoch 1/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.1931     \n",
      "Epoch 2/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.1946     \n",
      "Epoch 3/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.1923     \n",
      "Epoch 4/5\n",
      "10033/10033 [==============================] - 1s - loss: 1.1916     \n",
      "Epoch 5/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.1912     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 53\n",
      "Epoch 1/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.1922     \n",
      "Epoch 2/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.1920     \n",
      "Epoch 3/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.1926     \n",
      "Epoch 4/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.1931     \n",
      "Epoch 5/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.1910     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 54\n",
      "Epoch 1/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.1885     \n",
      "Epoch 2/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.1909     \n",
      "Epoch 3/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.1890     \n",
      "Epoch 4/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.1911     \n",
      "Epoch 5/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.1914     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 55\n",
      "Epoch 1/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.1902     \n",
      "Epoch 2/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.1897     \n",
      "Epoch 3/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.1883     \n",
      "Epoch 4/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.1897     \n",
      "Epoch 5/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.1893     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 56\n",
      "Epoch 1/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.1900     \n",
      "Epoch 2/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.1876     \n",
      "Epoch 3/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.1858     \n",
      "Epoch 4/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.1889     \n",
      "Epoch 5/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.1904     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 57\n",
      "Epoch 1/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.1872     \n",
      "Epoch 2/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.1880     \n",
      "Epoch 3/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.1867     \n",
      "Epoch 4/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.1880     \n",
      "Epoch 5/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.1873     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 58\n",
      "Epoch 1/5\n",
      "10033/10033 [==============================] - 3s - loss: 1.1896     \n",
      "Epoch 2/5\n",
      "10033/10033 [==============================] - 3s - loss: 1.1884     \n",
      "Epoch 3/5\n",
      "10033/10033 [==============================] - 3s - loss: 1.1882     \n",
      "Epoch 4/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.1871     \n",
      "Epoch 5/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.1862     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 59\n",
      "Epoch 1/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.1847     \n",
      "Epoch 2/5\n",
      "10033/10033 [==============================] - 1s - loss: 1.1869     \n",
      "Epoch 3/5\n",
      "10033/10033 [==============================] - 1s - loss: 1.1863     \n",
      "Epoch 4/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.1871     \n",
      "Epoch 5/5\n",
      "10033/10033 [==============================] - 2s - loss: 1.1851     \n"
     ]
    }
   ],
   "source": [
    "# train the Greek model\n",
    "for iteration in range(1, 60): # Make this 26\n",
    "    print()\n",
    "    print('-' * 50)\n",
    "    print('Iteration', iteration)\n",
    "    model_grk.fit(X_train_grk, X_train_labels_grk,\n",
    "              batch_size=128,\n",
    "              epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create the 500 test data\n",
    "test_data_500 = np.zeros((500, maxlen, len(chars)), dtype=np.bool)\n",
    "\n",
    "# Pick 100 substrings at random from each language\n",
    "eng_test_indices = np.random.randint(0, X_test_eng.shape[0], size=100)\n",
    "frn_test_indices = np.random.randint(0, X_test_frn.shape[0], size=100)\n",
    "rus_test_indices = np.random.randint(0, X_test_rus.shape[0], size=100)\n",
    "ger_test_indices = np.random.randint(0, X_test_ger.shape[0], size=100)\n",
    "grk_test_indices = np.random.randint(0, X_test_grk.shape[0], size=100)\n",
    "\n",
    "# Fill the data\n",
    "test_data_500[:100] = X_test_eng[eng_test_indices,:,:]\n",
    "test_data_500[100:200] = X_test_frn[frn_test_indices,:,:]\n",
    "test_data_500[200:300] = X_test_rus[rus_test_indices,:,:]\n",
    "test_data_500[300:400] = X_test_ger[ger_test_indices,:,:]\n",
    "test_data_500[400:] = X_test_grk[grk_test_indices,:,:]\n",
    "\n",
    "# Create the labels\n",
    "test_labels_500 = np.concatenate(([1]*100, [0]*100, [2]*100, [3]*100, [4]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/5 [=====>........................] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "test_predict_500 = np.zeros(500)\n",
    "#test_y_hat_500 = np.zeros(500)\n",
    "\n",
    "for t in range(test_data_500.shape[0]):\n",
    "    letter_string = ''\n",
    "    for letter in range(maxlen):\n",
    "        letter_ind = np.where(test_data_500[t,letter,:]==1)[0][0]\n",
    "        letter_string += chars[letter_ind]\n",
    "    letter_string_vect = test_vectorization(letter_string, maxlen, chars, char_indices)\n",
    "    \n",
    "    test_predict_eng = model_eng.predict(letter_string_vect, batch_size=1, verbose=1)\n",
    "    test_predict_frn = model_frn.predict(letter_string_vect, batch_size=1, verbose=1)\n",
    "    test_predict_rus = model_rus.predict(letter_string_vect, batch_size=1, verbose=1)\n",
    "    test_predict_ger = model_ger.predict(letter_string_vect, batch_size=1, verbose=1)\n",
    "    test_predict_grk = model_grk.predict(letter_string_vect, batch_size=1, verbose=1)\n",
    "    total_prob_eng = 1\n",
    "    total_prob_frn = 1\n",
    "    total_prob_rus = 1\n",
    "    total_prob_ger = 1\n",
    "    total_prob_grk = 1\n",
    "    for p in range(len(test_predict_eng)):\n",
    "        \"\"\"if len(np.where(test_data_200[t,p,:]==1)[0]) == 0:\n",
    "            print('BREAK')\n",
    "            break\"\"\"\n",
    "        char_ind = np.where(test_data_500[t,p,:]==1)[0][0]\n",
    "        # English probability\n",
    "        char_prob_eng = test_predict_eng[p, char_ind]\n",
    "        total_prob_eng *= char_prob_eng\n",
    "        # French probability\n",
    "        char_prob_frn = test_predict_frn[p, char_ind]\n",
    "        total_prob_frn *= char_prob_frn\n",
    "        # Russian probability\n",
    "        char_prob_rus = test_predict_rus[p, char_ind]\n",
    "        total_prob_rus *= char_prob_rus\n",
    "        # German probability\n",
    "        char_prob_ger = test_predict_ger[p, char_ind]\n",
    "        total_prob_ger *= char_prob_ger\n",
    "        # Greek probability\n",
    "        char_prob_grk = test_predict_grk[p, char_ind]\n",
    "        total_prob_grk *= char_prob_grk\n",
    "    total_probs = [total_prob_frn, total_prob_eng, total_prob_rus, total_prob_ger, total_prob_grk]\n",
    "    prediction = np.argmax(total_probs)\n",
    "    test_predict_500[t] = prediction\n",
    "    #test_y_hat_500[t] = np.log(total_prob_eng) - np.log(total_prob_frn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.698\n"
     ]
    }
   ],
   "source": [
    "accuracy_vect = np.nonzero(test_labels_500 - test_predict_500)\n",
    "accuracy = 1 - (len(accuracy_vect[0]) / 500.)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy from one run of these models is quite good at nearly 70%.  This is good accuracy compared to the basic model assigned.  There may be some mild variation in accuracy due to the random sampling of 100 strings per language from the test data.  The models are generally the same as before, and I think the improvement comes from having several languages with very distinct character sets.  With different character sets, the languages should be much easier to distinguish."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra Credit - English and Russian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We concluded in the previous extra credit portion that our high accuracy may be driven by the fact that some languages being used had distinct character sets.  In order to isolate this, we chose two very different languages - English and Russian.  The following tests are like those with English and French."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Corpus Length:\t 10746\n",
      "Russian Corpus Length:\t 11930\n",
      "Total Chars:\t 77\n",
      "English 5-char sequences:\t 10741\n",
      "Russian 5-char sequences:\t 11925\n"
     ]
    }
   ],
   "source": [
    "path_eng = get_file('eng.txt', origin='https://raw.githubusercontent.com/GT-CSE6240/proj2/master/data/eng.txt')\n",
    "text_eng = open(path_eng).read().lower()\n",
    "print('English Corpus Length:\\t', len(text_eng))\n",
    "\n",
    "path_rus = 'data/rus.txt'\n",
    "text_rus = open(path_rus).read().lower()\n",
    "print('Russian Corpus Length:\\t', len(text_rus))\n",
    "\n",
    "# Get chars from two texts\n",
    "chars_from_eng = sorted(list(set(text_eng)))\n",
    "chars_from_rus = sorted(list(set(text_rus)))\n",
    "\n",
    "# Combine chars from two languages into one chars list\n",
    "#######################\n",
    "# Code between hash lines taken from \n",
    "# http://stackoverflow.com/questions/2151517/pythonic-way-to-create-union-of-all-values-contained-in-multiple-lists\n",
    "results_list = [chars_from_eng, chars_from_rus]\n",
    "chars = list(set().union(*results_list))\n",
    "#######################\n",
    "\n",
    "# Get dictionaries of chars and their index in the chars list\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "print('Total Chars:\\t', len(chars))\n",
    "\n",
    "# Break up English text into 5 char segments, shifting one char at a\n",
    "# time when making new segments\n",
    "maxlen = 5\n",
    "step = 1\n",
    "char5_strings_eng = []\n",
    "next_chars_eng = []\n",
    "for i in range(0, len(text_eng) - maxlen, step):\n",
    "    char5_strings_eng.append(text_eng[i: i + maxlen])\n",
    "    next_chars_eng.append(text_eng[i + maxlen])\n",
    "print('English 5-char sequences:\\t', len(char5_strings_eng))\n",
    "\n",
    "# Break up Russian text into 5 char segments, shifting one char at a\n",
    "# time when making new segments\n",
    "maxlen = 5\n",
    "step = 1\n",
    "char5_strings_rus = []\n",
    "next_chars_rus = []\n",
    "for i in range(0, len(text_rus) - maxlen, step):\n",
    "    char5_strings_rus.append(text_rus[i: i + maxlen])\n",
    "    next_chars_rus.append(text_rus[i + maxlen])\n",
    "print('Russian 5-char sequences:\\t', len(char5_strings_rus))\n",
    "\n",
    "# Get the labels for the datasets\n",
    "# 1=English, 0=Russian\n",
    "labels_eng = np.array([1]*len(char5_strings_eng))\n",
    "labels_rus = np.array([0]*len(char5_strings_rus))\n",
    "\n",
    "# Do an 80/20 split to get training and test data for both English and Russian\n",
    "training_data_eng, testing_data_eng, training_labels_eng, testing_labels_eng = train_test_split(\n",
    "        char5_strings_eng, labels_eng, test_size=0.2, random_state=0)\n",
    "\n",
    "training_data_rus, testing_data_rus, training_labels_rus, testing_labels_rus = train_test_split(\n",
    "        char5_strings_rus, labels_rus, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Method to vectorize a dataset\n",
    "def vectorization(char5_strings, maxlen, chars, char_indices, next_chars):\n",
    "    X = np.zeros((len(char5_strings), maxlen, len(chars)), dtype=np.bool)\n",
    "    y = np.zeros((len(char5_strings), len(chars)), dtype=np.bool)\n",
    "    for i, char5_string in enumerate(char5_strings):\n",
    "        for t, char in enumerate(char5_string):\n",
    "            X[i, t, char_indices[char]] = 1\n",
    "        y[i, char_indices[next_chars[i]]] = 1\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_eng, X_train_labels_eng = vectorization(training_data_eng, maxlen, chars, char_indices, next_chars_eng)\n",
    "X_test_eng, X_test_labels_eng = vectorization(testing_data_eng, maxlen, chars, char_indices, next_chars_eng)\n",
    "\n",
    "X_train_rus, X_train_labels_rus = vectorization(training_data_rus, maxlen, chars, char_indices, next_chars_rus)\n",
    "X_test_rus, X_test_labels_rus = vectorization(testing_data_rus, maxlen, chars, char_indices, next_chars_rus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building English model\n",
      "Building Russian model\n"
     ]
    }
   ],
   "source": [
    "# Build the English model: a single LSTM\n",
    "print('Building English model')\n",
    "model_eng = Sequential()\n",
    "model_eng.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "model_eng.add(Dense(len(chars)))\n",
    "model_eng.add(Activation('softmax'))\n",
    "\n",
    "optimizer = RMSprop(lr=0.01)\n",
    "model_eng.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
    "\n",
    "\n",
    "# Build the Russian model: a single LSTM\n",
    "print('Building Russian model')\n",
    "model_rus = Sequential()\n",
    "model_rus.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "model_rus.add(Dense(len(chars)))\n",
    "model_rus.add(Activation('softmax'))\n",
    "\n",
    "model_rus.compile(loss='categorical_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 3s - loss: 3.0380     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 2.9478     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 2.9383     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 2.9323     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 2.9175     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 2.9036     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 2.8803     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 2.8516     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 2.8160     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 2.7675     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 3\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 2.7152     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 2.6467     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 2.5760     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 2.5028     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 2.4186     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 4\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 2.3377     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 2.2533     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 2.1766     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 2.1034     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 2.0344     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 5\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.9718     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.9069     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.8591     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.8103     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.7701     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 6\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.7357     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.7013     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.6762     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.6484     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.6214     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 7\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.6100     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.5827     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.5671     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.5517     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.5375     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 8\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.5278     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.5087     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.5045     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.4928     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.4823     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 9\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.4706     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.4640     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.4576     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.4544     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.4404     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 10\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.4349     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.4357     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.4272     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.4229     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.4167     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 11\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.4146     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.4059     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.4047     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3957     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3961     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 12\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3916     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3890     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3885     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3771     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3788     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 13\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3732     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3726     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3641     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3636     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3615     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 14\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3628     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3560     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3563     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3535     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3497     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 15\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3469     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3424     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3426     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3429     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3431     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 16\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3379     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3373     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3330     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3349     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3290     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 17\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3315     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3242     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3244     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3220     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3220     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 18\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3200     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3155     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3193     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3160     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3149     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 19\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3158     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3121     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3124     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3089     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3081     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 20\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3054     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3031     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3044     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3039     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3008     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 21\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3007     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.3000     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2999     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2953     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2927     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 22\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2942     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2908     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2914     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2906     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2911     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 23\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2913     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2891     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2864     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2877     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2863     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 24\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2842     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2851     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2812     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2827     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2794     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 25\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2784     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2811     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2779     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2766     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2788     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 26\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2771     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2753     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2729     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2716     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2726     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 27\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2731     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2727     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2690     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2680     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2668     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 28\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2696     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2640     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2680     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2664     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2684     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 29\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2653     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2670     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2657     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2633     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2614     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 30\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2630     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2597     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2621     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2624     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2592     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 31\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2560     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2577     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2573     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2595     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2540     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 32\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2568     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2576     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2558     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2550     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2546     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 33\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2539     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2539     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2519     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2555     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2487     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 34\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2521     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2540     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2509     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2526     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2497     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 35\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2497     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2499     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2489     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2472     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2482     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 36\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2491     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2488     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2430     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2486     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2462     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 37\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2405     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2454     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2440     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2424     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2455     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 38\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2423     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2448     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2430     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2447     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2423     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 39\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2399     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2395     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2419     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2415     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2363     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 40\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2418     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2385     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2372     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2385     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2399     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 41\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2380     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2389     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2350     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2360     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2408     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 42\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2381     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2387     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2313     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2354     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2319     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 43\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2341     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2318     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2341     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2356     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2324     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 44\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2319     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2333     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2347     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2330     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2322     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 45\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2335     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2296     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2292     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2309     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2323     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 46\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2305     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2283     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2304     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2276     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2312     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 47\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2293     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2301     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2300     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2299     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2325     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 48\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2294     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2285     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2264     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2281     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2275     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 49\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2287     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2269     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2253     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2255     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2253     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 50\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2258     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2258     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2250     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2237     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2246     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 51\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2237     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2261     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2212     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2234     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2228     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 52\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2204     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2239     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2233     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2223     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2261     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 53\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2198     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2210     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2209     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2215     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2196     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 54\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2223     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2206     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2195     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2171     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2183     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 55\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2211     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2183     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2193     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2195     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2182     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 56\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2218     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2178     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2203     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2166     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2151     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 57\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2195     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2178     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2187     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2134     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2180     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 58\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2179     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2180     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2180     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2163     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2152     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 59\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2163     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 1s - loss: 1.2147     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2171     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2149     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2153     \n"
     ]
    }
   ],
   "source": [
    "# train the English model\n",
    "for iteration in range(1, 60): # Make it 26\n",
    "    print()\n",
    "    print('-' * 50)\n",
    "    print('Iteration', iteration)\n",
    "    model_eng.fit(X_train_eng, X_train_labels_eng,\n",
    "              batch_size=128,\n",
    "              epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1\n",
      "Epoch 1/5\n",
      "9540/9540 [==============================] - 3s - loss: 3.2547     \n",
      "Epoch 2/5\n",
      "9540/9540 [==============================] - 2s - loss: 3.1812     \n",
      "Epoch 3/5\n",
      "9540/9540 [==============================] - 2s - loss: 3.1692     \n",
      "Epoch 4/5\n",
      "9540/9540 [==============================] - 2s - loss: 3.1535     \n",
      "Epoch 5/5\n",
      "9540/9540 [==============================] - 2s - loss: 3.1270     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2\n",
      "Epoch 1/5\n",
      "9540/9540 [==============================] - 2s - loss: 3.0967     \n",
      "Epoch 2/5\n",
      "9540/9540 [==============================] - 2s - loss: 3.0572     \n",
      "Epoch 3/5\n",
      "9540/9540 [==============================] - 2s - loss: 3.0018     \n",
      "Epoch 4/5\n",
      "9540/9540 [==============================] - 2s - loss: 2.9357     \n",
      "Epoch 5/5\n",
      "9540/9540 [==============================] - 2s - loss: 2.8563     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 3\n",
      "Epoch 1/5\n",
      "9540/9540 [==============================] - 2s - loss: 2.7665     \n",
      "Epoch 2/5\n",
      "9540/9540 [==============================] - 2s - loss: 2.6654     \n",
      "Epoch 3/5\n",
      "9540/9540 [==============================] - 2s - loss: 2.5646     \n",
      "Epoch 4/5\n",
      "9540/9540 [==============================] - 2s - loss: 2.4598     \n",
      "Epoch 5/5\n",
      "9540/9540 [==============================] - 2s - loss: 2.3614     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 4\n",
      "Epoch 1/5\n",
      "9540/9540 [==============================] - 2s - loss: 2.2652     \n",
      "Epoch 2/5\n",
      "9540/9540 [==============================] - 2s - loss: 2.1748     \n",
      "Epoch 3/5\n",
      "9540/9540 [==============================] - 2s - loss: 2.0914     \n",
      "Epoch 4/5\n",
      "9540/9540 [==============================] - 2s - loss: 2.0127     \n",
      "Epoch 5/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.9468     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 5\n",
      "Epoch 1/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.8772     \n",
      "Epoch 2/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.8243     \n",
      "Epoch 3/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.7714     \n",
      "Epoch 4/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.7297     \n",
      "Epoch 5/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.6833     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 6\n",
      "Epoch 1/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.6567     \n",
      "Epoch 2/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.6231     \n",
      "Epoch 3/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.5938     \n",
      "Epoch 4/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.5765     \n",
      "Epoch 5/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.5546     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 7\n",
      "Epoch 1/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.5304     \n",
      "Epoch 2/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.5190     \n",
      "Epoch 3/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.5008     \n",
      "Epoch 4/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.4874     \n",
      "Epoch 5/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.4674     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 8\n",
      "Epoch 1/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.4650     \n",
      "Epoch 2/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.4520     \n",
      "Epoch 3/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.4333     \n",
      "Epoch 4/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.4330     \n",
      "Epoch 5/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.4243     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 9\n",
      "Epoch 1/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.4099     \n",
      "Epoch 2/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.4078     \n",
      "Epoch 3/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.3975     \n",
      "Epoch 4/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.3867     \n",
      "Epoch 5/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.3803     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 10\n",
      "Epoch 1/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.3786     \n",
      "Epoch 2/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.3738     \n",
      "Epoch 3/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.3650     \n",
      "Epoch 4/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.3675     \n",
      "Epoch 5/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.3587     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 11\n",
      "Epoch 1/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.3538     \n",
      "Epoch 2/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.3448     \n",
      "Epoch 3/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.3439     \n",
      "Epoch 4/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.3390     \n",
      "Epoch 5/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.3393     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 12\n",
      "Epoch 1/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.3327     \n",
      "Epoch 2/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.3317     \n",
      "Epoch 3/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.3248     \n",
      "Epoch 4/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.3178     \n",
      "Epoch 5/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.3151     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 13\n",
      "Epoch 1/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.3136     \n",
      "Epoch 2/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.3135     \n",
      "Epoch 3/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.3104     \n",
      "Epoch 4/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.3041     \n",
      "Epoch 5/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.3007     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 14\n",
      "Epoch 1/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.3016     \n",
      "Epoch 2/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.2956     \n",
      "Epoch 3/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.2902     \n",
      "Epoch 4/5\n",
      "9540/9540 [==============================] - 1s - loss: 1.2970     \n",
      "Epoch 5/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.2868     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 15\n",
      "Epoch 1/5\n",
      "9540/9540 [==============================] - 1s - loss: 1.2858     \n",
      "Epoch 2/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.2808     \n",
      "Epoch 3/5\n",
      "9540/9540 [==============================] - 1s - loss: 1.2868     \n",
      "Epoch 4/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.2795     \n",
      "Epoch 5/5\n",
      "9540/9540 [==============================] - 1s - loss: 1.2789     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 16\n",
      "Epoch 1/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.2748     \n",
      "Epoch 2/5\n",
      "9540/9540 [==============================] - 1s - loss: 1.2745     \n",
      "Epoch 3/5\n",
      "9540/9540 [==============================] - 1s - loss: 1.2710     \n",
      "Epoch 4/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.2725     \n",
      "Epoch 5/5\n",
      "9540/9540 [==============================] - 1s - loss: 1.2682     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 17\n",
      "Epoch 1/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.2643     \n",
      "Epoch 2/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.2666     \n",
      "Epoch 3/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.2599     \n",
      "Epoch 4/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.2616     \n",
      "Epoch 5/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.2596     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 18\n",
      "Epoch 1/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.2549     \n",
      "Epoch 2/5\n",
      "9540/9540 [==============================] - 1s - loss: 1.2573     \n",
      "Epoch 3/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.2590     \n",
      "Epoch 4/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.2527     \n",
      "Epoch 5/5\n",
      "9540/9540 [==============================] - 1s - loss: 1.2487     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 19\n",
      "Epoch 1/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.2504     \n",
      "Epoch 2/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.2458     \n",
      "Epoch 3/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.2503     \n",
      "Epoch 4/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.2440     \n",
      "Epoch 5/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.2443     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 20\n",
      "Epoch 1/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.2401     \n",
      "Epoch 2/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.2404     \n",
      "Epoch 3/5\n",
      "9540/9540 [==============================] - 62s - loss: 1.2370    \n",
      "Epoch 4/5\n",
      "9540/9540 [==============================] - 3s - loss: 1.2382     \n",
      "Epoch 5/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.2387     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 21\n",
      "Epoch 1/5\n",
      "9540/9540 [==============================] - 3s - loss: 1.2335     \n",
      "Epoch 2/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.2349     \n",
      "Epoch 3/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.2336     \n",
      "Epoch 4/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.2335     \n",
      "Epoch 5/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.2300     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 22\n",
      "Epoch 1/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.2302     \n",
      "Epoch 2/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.2287     \n",
      "Epoch 3/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.2278     \n",
      "Epoch 4/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.2285     \n",
      "Epoch 5/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.2237     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 23\n",
      "Epoch 1/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.2225     \n",
      "Epoch 2/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.2216     \n",
      "Epoch 3/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.2210     \n",
      "Epoch 4/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.2213     \n",
      "Epoch 5/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.2248     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 24\n",
      "Epoch 1/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.2223     \n",
      "Epoch 2/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.2172     \n",
      "Epoch 3/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.2171     \n",
      "Epoch 4/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.2184     \n",
      "Epoch 5/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.2148     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 25\n",
      "Epoch 1/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.2113     \n",
      "Epoch 2/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.2167     \n",
      "Epoch 3/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.2101     \n",
      "Epoch 4/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.2125     \n",
      "Epoch 5/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.2122     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 26\n",
      "Epoch 1/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.2090     \n",
      "Epoch 2/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.2079     \n",
      "Epoch 3/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.2060     \n",
      "Epoch 4/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.2083     \n",
      "Epoch 5/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.2077     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 27\n",
      "Epoch 1/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.2059     \n",
      "Epoch 2/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.2057     \n",
      "Epoch 3/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.2038     \n",
      "Epoch 4/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1995     \n",
      "Epoch 5/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.2017     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 28\n",
      "Epoch 1/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.2003     \n",
      "Epoch 2/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.2010     \n",
      "Epoch 3/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1998     \n",
      "Epoch 4/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1992     \n",
      "Epoch 5/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1999     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 29\n",
      "Epoch 1/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1983     \n",
      "Epoch 2/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1980     \n",
      "Epoch 3/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1957     \n",
      "Epoch 4/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1955     \n",
      "Epoch 5/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1965     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 30\n",
      "Epoch 1/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1953     \n",
      "Epoch 2/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1970     \n",
      "Epoch 3/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1940     \n",
      "Epoch 4/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1921     \n",
      "Epoch 5/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1918     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 31\n",
      "Epoch 1/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1949     \n",
      "Epoch 2/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1925     \n",
      "Epoch 3/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1921     \n",
      "Epoch 4/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1899     \n",
      "Epoch 5/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1900     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 32\n",
      "Epoch 1/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1901     \n",
      "Epoch 2/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1891     \n",
      "Epoch 3/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1875     \n",
      "Epoch 4/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1867     \n",
      "Epoch 5/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1883     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 33\n",
      "Epoch 1/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1846     \n",
      "Epoch 2/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1861     \n",
      "Epoch 3/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1863     \n",
      "Epoch 4/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1838     \n",
      "Epoch 5/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1862     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 34\n",
      "Epoch 1/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1835     \n",
      "Epoch 2/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1855     \n",
      "Epoch 3/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1839     \n",
      "Epoch 4/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1816     \n",
      "Epoch 5/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1831     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 35\n",
      "Epoch 1/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1829     \n",
      "Epoch 2/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1775     \n",
      "Epoch 3/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1803     \n",
      "Epoch 4/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1796     \n",
      "Epoch 5/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1794     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 36\n",
      "Epoch 1/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1801     \n",
      "Epoch 2/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1781     \n",
      "Epoch 3/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1778     \n",
      "Epoch 4/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1787     \n",
      "Epoch 5/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1800     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 37\n",
      "Epoch 1/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1743     \n",
      "Epoch 2/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1770     \n",
      "Epoch 3/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1766     \n",
      "Epoch 4/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1767     \n",
      "Epoch 5/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1765     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 38\n",
      "Epoch 1/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1738     \n",
      "Epoch 2/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1753     \n",
      "Epoch 3/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1738     \n",
      "Epoch 4/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1730     \n",
      "Epoch 5/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1738     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 39\n",
      "Epoch 1/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1725     \n",
      "Epoch 2/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1734     \n",
      "Epoch 3/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1721     \n",
      "Epoch 4/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1738     \n",
      "Epoch 5/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1700     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 40\n",
      "Epoch 1/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1704     \n",
      "Epoch 2/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1705     \n",
      "Epoch 3/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1710     \n",
      "Epoch 4/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1702     \n",
      "Epoch 5/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1715     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 41\n",
      "Epoch 1/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1683     \n",
      "Epoch 2/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1711     \n",
      "Epoch 3/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1674     \n",
      "Epoch 4/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1683     \n",
      "Epoch 5/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1651     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 42\n",
      "Epoch 1/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1702     \n",
      "Epoch 2/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1672     \n",
      "Epoch 3/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1677     \n",
      "Epoch 4/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1641     \n",
      "Epoch 5/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1687     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 43\n",
      "Epoch 1/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1674     \n",
      "Epoch 2/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1651     \n",
      "Epoch 3/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1644     \n",
      "Epoch 4/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1666     \n",
      "Epoch 5/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1648     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 44\n",
      "Epoch 1/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1639     \n",
      "Epoch 2/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1643     \n",
      "Epoch 3/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1619     \n",
      "Epoch 4/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1607     \n",
      "Epoch 5/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1585     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 45\n",
      "Epoch 1/5\n",
      "9540/9540 [==============================] - 3s - loss: 1.1646     \n",
      "Epoch 2/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1622     \n",
      "Epoch 3/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1631     \n",
      "Epoch 4/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1618     \n",
      "Epoch 5/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1620     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 46\n",
      "Epoch 1/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1606     \n",
      "Epoch 2/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1585     \n",
      "Epoch 3/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1586     \n",
      "Epoch 4/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1599     \n",
      "Epoch 5/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1596     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 47\n",
      "Epoch 1/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1576     \n",
      "Epoch 2/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1603     \n",
      "Epoch 3/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1553     \n",
      "Epoch 4/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1609     \n",
      "Epoch 5/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1569     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 48\n",
      "Epoch 1/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1583     \n",
      "Epoch 2/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1566     \n",
      "Epoch 3/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1557     \n",
      "Epoch 4/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1560     \n",
      "Epoch 5/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1570     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 49\n",
      "Epoch 1/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1591     \n",
      "Epoch 2/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1546     \n",
      "Epoch 3/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1552     \n",
      "Epoch 4/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1541     \n",
      "Epoch 5/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1547     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 50\n",
      "Epoch 1/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1531     \n",
      "Epoch 2/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1556     \n",
      "Epoch 3/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1550     \n",
      "Epoch 4/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1572     \n",
      "Epoch 5/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1529     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 51\n",
      "Epoch 1/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1504     \n",
      "Epoch 2/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1536     \n",
      "Epoch 3/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1522     \n",
      "Epoch 4/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1525     \n",
      "Epoch 5/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1535     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 52\n",
      "Epoch 1/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1522     \n",
      "Epoch 2/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1510     \n",
      "Epoch 3/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1504     \n",
      "Epoch 4/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1509     \n",
      "Epoch 5/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1511     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 53\n",
      "Epoch 1/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1519     \n",
      "Epoch 2/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1504     \n",
      "Epoch 3/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1508     \n",
      "Epoch 4/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1464     \n",
      "Epoch 5/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1503     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 54\n",
      "Epoch 1/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1494     \n",
      "Epoch 2/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1499     \n",
      "Epoch 3/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1498     \n",
      "Epoch 4/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1501     \n",
      "Epoch 5/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1499     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 55\n",
      "Epoch 1/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1509     \n",
      "Epoch 2/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1480     \n",
      "Epoch 3/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1514     \n",
      "Epoch 4/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1459     \n",
      "Epoch 5/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1494     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 56\n",
      "Epoch 1/5\n",
      "9540/9540 [==============================] - 3s - loss: 1.1483     \n",
      "Epoch 2/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1501     \n",
      "Epoch 3/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1455     \n",
      "Epoch 4/5\n",
      "9540/9540 [==============================] - 3s - loss: 1.1469     \n",
      "Epoch 5/5\n",
      "9540/9540 [==============================] - 3s - loss: 1.1460     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 57\n",
      "Epoch 1/5\n",
      "9540/9540 [==============================] - 3s - loss: 1.1455     \n",
      "Epoch 2/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1450     \n",
      "Epoch 3/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1463     \n",
      "Epoch 4/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1423     \n",
      "Epoch 5/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1469     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 58\n",
      "Epoch 1/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1408     \n",
      "Epoch 2/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1440     \n",
      "Epoch 3/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1445     \n",
      "Epoch 4/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1456     \n",
      "Epoch 5/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1471     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 59\n",
      "Epoch 1/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1417     \n",
      "Epoch 2/5\n",
      "9540/9540 [==============================] - 3s - loss: 1.1464     \n",
      "Epoch 3/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1449     \n",
      "Epoch 4/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1458     \n",
      "Epoch 5/5\n",
      "9540/9540 [==============================] - 2s - loss: 1.1422     \n"
     ]
    }
   ],
   "source": [
    "# train the Russian model\n",
    "for iteration in range(1, 60): # Make this 26\n",
    "    print()\n",
    "    print('-' * 50)\n",
    "    print('Iteration', iteration)\n",
    "    model_rus.fit(X_train_rus, X_train_labels_rus,\n",
    "              batch_size=128,\n",
    "              epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the 200 test data\n",
    "test_data_200 = np.zeros((200, maxlen, len(chars)), dtype=np.bool)\n",
    "\n",
    "# Pick 100 substrings at random from each language\n",
    "eng_test_indices = np.random.randint(0, X_test_eng.shape[0], size=100)\n",
    "rus_test_indices = np.random.randint(0, X_test_rus.shape[0], size=100)\n",
    "\n",
    "# Fill the data\n",
    "test_data_200[:100] = X_test_eng[eng_test_indices,:,:]\n",
    "test_data_200[100:] = X_test_rus[rus_test_indices,:,:]\n",
    "\n",
    "# Create the labels\n",
    "test_labels_200 = np.concatenate(([1]*100, [0]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Vectorize test string\n",
    "def test_vectorization(test_string, maxlen, chars, char_indices):\n",
    "    # Create array to handle broken up test string\n",
    "    test_string_data = []\n",
    "    \n",
    "    # Break up test string\n",
    "    for ind in range(min(maxlen, len(test_string))):\n",
    "        test_string_data.append(test_string[:ind])\n",
    "   \n",
    "    # Create X\n",
    "    X = np.zeros((len(test_string_data), maxlen, len(chars)), dtype=np.bool)\n",
    "    for i, test_string_entry in enumerate(test_string_data):\n",
    "        for t, char in enumerate(test_string_entry):\n",
    "            X[i, t, char_indices[char]] = 1\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/5 [=====>........................] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "test_predict_200 = np.zeros(200)\n",
    "test_y_hat_200 = np.zeros(200)\n",
    "\n",
    "for t in range(test_data_200.shape[0]):\n",
    "    letter_string = ''\n",
    "    for letter in range(maxlen):\n",
    "        letter_ind = np.where(test_data_200[t,letter,:]==1)[0][0]\n",
    "        letter_string += chars[letter_ind]\n",
    "    letter_string_vect = test_vectorization(letter_string, maxlen, chars, char_indices)\n",
    "    \n",
    "    test_predict_eng = model_eng.predict(letter_string_vect, batch_size=1, verbose=1)\n",
    "    test_predict_rus = model_rus.predict(letter_string_vect, batch_size=1, verbose=1)\n",
    "    total_prob_eng = 1\n",
    "    total_prob_rus = 1\n",
    "    for p in range(len(test_predict_eng)):\n",
    "        \"\"\"if len(np.where(test_data_200[t,p,:]==1)[0]) == 0:\n",
    "            print('BREAK')\n",
    "            break\"\"\"\n",
    "        char_ind = np.where(test_data_200[t,p,:]==1)[0][0]\n",
    "        # English probability\n",
    "        char_prob_eng = test_predict_eng[p, char_ind]\n",
    "        total_prob_eng *= char_prob_eng\n",
    "        # Russian probability\n",
    "        char_prob_rus = test_predict_rus[p, char_ind]\n",
    "        total_prob_rus *= char_prob_rus\n",
    "    prediction = 1 if (np.log(total_prob_eng) > np.log(total_prob_rus)) else 0\n",
    "    test_predict_200[t] = prediction\n",
    "    test_y_hat_200[t] = np.log(total_prob_eng) - np.log(total_prob_rus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "accuracy_vect = np.nonzero(test_labels_200 - test_predict_200)\n",
    "accuracy = 1 - (len(accuracy_vect[0]) / 200.)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAoMAAAFqCAYAAABhzVBZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n0zHze6IAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x140ebe860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Code from\n",
    "# http://stackoverflow.com/questions/42894871/how-to-plot-multiple-roc-curves-in-one-plot-with-legend-and-auc-scores-in-python\n",
    "\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "plt.figure(0).clf()\n",
    "\n",
    "auc = metrics.roc_auc_score(test_labels_200, test_y_hat_200)\n",
    "fpr, tpr, thresholds = metrics.roc_curve(test_labels_200, test_y_hat_200)\n",
    "plt.semilogx(basex = math.e)\n",
    "plt.plot(fpr, tpr, label=\"AUC=\"+str(auc))\n",
    "#plt.plot([0, 1], [0, 1], color='gray')\n",
    "\n",
    "plt.legend(loc=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We note here the perfect accuracy of the lanugage predictions and the AUC of 1.  We believe, as stated, that this is due to the distinctness of written English and Russian."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra Credit - Bidirectional LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also considered the use of a bidirectional LSTM.  This would not just look at subsequent letters given past letters, but also previous letters given later ones.  We suspected that this would lead to greater accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Corpus Length:\t 10746\n",
      "French Corpus Length:\t 12009\n",
      "Total Chars:\t 44\n",
      "English nb sequences:\t 10741\n",
      "French nb sequences:\t 12004\n"
     ]
    }
   ],
   "source": [
    "path_eng = get_file('eng.txt', origin='https://raw.githubusercontent.com/GT-CSE6240/proj2/master/data/eng.txt')\n",
    "text_eng = open(path_eng).read().lower()\n",
    "print('English Corpus Length:\\t', len(text_eng))\n",
    "\n",
    "path_frn = get_file('frn.txt', origin='https://raw.githubusercontent.com/GT-CSE6240/proj2/master/data/frn.txt')\n",
    "text_frn = open(path_frn).read().lower()\n",
    "print('French Corpus Length:\\t', len(text_frn))\n",
    "\n",
    "# Get chars from two texts\n",
    "chars_from_eng = sorted(list(set(text_eng)))\n",
    "chars_from_frn = sorted(list(set(text_frn)))\n",
    "\n",
    "# Combine chars from two languages into one chars list\n",
    "#######################\n",
    "# Code between hash lines taken from \n",
    "# http://stackoverflow.com/questions/2151517/pythonic-way-to-create-union-of-all-values-contained-in-multiple-lists\n",
    "results_list = [chars_from_eng, chars_from_frn]\n",
    "chars = list(set().union(*results_list))\n",
    "#######################\n",
    "\n",
    "# Get dictionaries of chars and their index in the chars list\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "print('Total Chars:\\t', len(chars))\n",
    "\n",
    "# Break up English text into 5 char segments, shifting one char at a\n",
    "# time when making new segments\n",
    "maxlen = 5\n",
    "step = 1\n",
    "char5_strings_eng = []\n",
    "next_chars_eng = []\n",
    "for i in range(0, len(text_eng) - maxlen, step):\n",
    "    char5_strings_eng.append(text_eng[i: i + maxlen])\n",
    "    next_chars_eng.append(text_eng[i + maxlen])\n",
    "print('English nb sequences:\\t', len(char5_strings_eng))\n",
    "\n",
    "# Break up French text into 5 char segments, shifting one char at a\n",
    "# time when making new segments\n",
    "maxlen = 5\n",
    "step = 1\n",
    "char5_strings_frn = []\n",
    "next_chars_frn = []\n",
    "for i in range(0, len(text_frn) - maxlen, step):\n",
    "    char5_strings_frn.append(text_frn[i: i + maxlen])\n",
    "    next_chars_frn.append(text_frn[i + maxlen])\n",
    "print('French nb sequences:\\t', len(char5_strings_frn))\n",
    "\n",
    "# Get the labels for the datasets\n",
    "# 1=English, 0=French\n",
    "labels_eng = np.array([1]*len(char5_strings_eng))\n",
    "labels_frn = np.array([0]*len(char5_strings_frn))\n",
    "\n",
    "# Do an 80/20 split to get training and test data for both English and French\n",
    "training_data_eng, testing_data_eng, training_labels_eng, testing_labels_eng = train_test_split(\n",
    "        char5_strings_eng, labels_eng, test_size=0.2, random_state=0)\n",
    "\n",
    "training_data_frn, testing_data_frn, training_labels_frn, testing_labels_frn = train_test_split(\n",
    "        char5_strings_frn, labels_frn, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Method to vectorize a dataset\n",
    "def vectorization(char5_strings, maxlen, chars, char_indices, next_chars):\n",
    "    X = np.zeros((len(char5_strings), maxlen, len(chars)), dtype=np.bool)\n",
    "    y = np.zeros((len(char5_strings), len(chars)), dtype=np.bool)\n",
    "    for i, char5_string in enumerate(char5_strings):\n",
    "        for t, char in enumerate(char5_string):\n",
    "            X[i, t, char_indices[char]] = 1\n",
    "        r = next_chars[i]\n",
    "        y[i, char_indices[next_chars[i]]] = 1\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_eng, X_train_labels_eng = vectorization(training_data_eng, maxlen, chars, char_indices, next_chars_eng)\n",
    "X_test_eng, X_test_labels_eng = vectorization(testing_data_eng, maxlen, chars, char_indices, next_chars_eng)\n",
    "\n",
    "X_train_frn, X_train_labels_frn = vectorization(training_data_frn, maxlen, chars, char_indices, next_chars_frn)\n",
    "X_test_frn, X_test_labels_frn = vectorization(testing_data_frn, maxlen, chars, char_indices, next_chars_frn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following 3 cells are taken from the following source (and the 2 cells after that take some parts from it) and modified as necessary: https://github.com/fchollet/keras/issues/1629"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fork (model, n=2):\n",
    "    forks = []\n",
    "    for i in range(n):\n",
    "        f = Sequential()\n",
    "        f.add (model)\n",
    "        forks.append(f)\n",
    "    return forks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 5, 44)\n",
      "(None, 128)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sam/miniconda3/lib/python3.5/site-packages/ipykernel/__main__.py:14: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "/Users/sam/miniconda3/lib/python3.5/site-packages/ipykernel/__main__.py:19: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n"
     ]
    }
   ],
   "source": [
    "# ENGLISH MODEL\n",
    "\n",
    "from keras.layers import Merge\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "left = Sequential()\n",
    "left.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "print(left.input_shape)\n",
    "print(left.output_shape)\n",
    "right = Sequential()\n",
    "right.add(LSTM(128, input_shape=(maxlen, len(chars)), go_backwards=True))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Merge([left, right], mode='sum'))\n",
    "\n",
    "#Add second Bidirectional LSTM layer\n",
    "left, right = fork(model)\n",
    "model_eng = Sequential()\n",
    "model_eng.add(Merge([left, right], mode='sum'))\n",
    "\n",
    "\n",
    "model_eng.add(Dense(len(chars)))\n",
    "model_eng.add(Activation('softmax'))\n",
    "\n",
    "sgd = SGD(lr=0.1, decay=1e-5, momentum=0.9, nesterov=True)\n",
    "model_eng.compile(loss='categorical_crossentropy', optimizer=sgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 5, 44)\n",
      "(None, 128)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sam/miniconda3/lib/python3.5/site-packages/ipykernel/__main__.py:11: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "/Users/sam/miniconda3/lib/python3.5/site-packages/ipykernel/__main__.py:16: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n"
     ]
    }
   ],
   "source": [
    "# FRENCH MODEL\n",
    "\n",
    "left = Sequential()\n",
    "left.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "print(left.input_shape)\n",
    "print(left.output_shape)\n",
    "right = Sequential()\n",
    "right.add(LSTM(128, input_shape=(maxlen, len(chars)), go_backwards=True))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Merge([left, right], mode='sum'))\n",
    "\n",
    "#Add second Bidirectional LSTM layer\n",
    "left, right = fork(model)\n",
    "model_frn = Sequential()\n",
    "model_frn.add(Merge([left, right], mode='sum'))\n",
    "\n",
    "\n",
    "model_frn.add(Dense(len(chars)))\n",
    "model_frn.add(Activation('softmax'))\n",
    "\n",
    "sgd = SGD(lr=0.1, decay=1e-5, momentum=0.9, nesterov=True)\n",
    "model_frn.compile(loss='categorical_crossentropy', optimizer=sgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 7s - loss: 3.0359     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 3s - loss: 2.9524     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.9423     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.9351     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.9286     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 3s - loss: 2.9283     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.9215     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 3s - loss: 2.9190     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.9146     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.9139     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 3\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.9096     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.9079     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.9048     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.9041     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.9015     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 4\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.8999     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.8983     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.8970     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.8923     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.8900     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 5\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.8891     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.8873     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.8882     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.8841     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.8840     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 6\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.8809     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.8799     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.8777     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.8783     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.8745     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 7\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.8729     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.8741     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.8741     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.8704     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.8675     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 8\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.8664     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.8675     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.8645     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.8628     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.8625     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 9\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.8639     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.8604     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.8597     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.8566     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.8549     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 10\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.8532     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.8522     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.8529     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.8507     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 3s - loss: 2.8480     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 11\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.8459     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.8474     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 3s - loss: 2.8447     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 4s - loss: 2.8436     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 3s - loss: 2.8419     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 12\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 3s - loss: 2.8419     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.8416     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.8388     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.8373     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.8340     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 13\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.8327     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.8345     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.8334     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.8303     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.8290     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 14\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 3s - loss: 2.8284     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.8257     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.8251     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.8239     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.8223     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 15\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 3s - loss: 2.8218     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 3s - loss: 2.8206     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.8199     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.8195     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.8159     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 16\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.8128     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.8133     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 3s - loss: 2.8140     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.8105     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.8071     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 17\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.8080     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.8079     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.8040     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.8059     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.8039     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 18\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.8012     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.7988     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.7969     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.7976     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.7917     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 19\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.7927     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.7911     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.7886     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.7898     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.7847     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 20\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.7826     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.7789     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.7783     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.7767     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.7728     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 21\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.7721     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.7711     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.7685     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.7643     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.7620     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 22\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.7611     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.7556     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.7543     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.7535     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.7421     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 23\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.7417     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.7384     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.7316     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.7272     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.7250     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 24\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.7153     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.7089     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.7057     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.6999     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.6951     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 25\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.6864     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.6748     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.6659     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.6565     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.6504     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 26\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.6384     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.6297     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.6095     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 3s - loss: 2.6034     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 3s - loss: 2.5878     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 27\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.5704     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.5577     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.5334     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.5280     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.5144     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 28\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.4854     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.4683     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.4525     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.4319     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.4028     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 29\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.3817     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.3608     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.3384     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.3061     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.2838     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 30\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.2485     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.2337     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.1922     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.1810     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.1389     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 31\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.1361     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.0875     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.0483     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.0263     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 2s - loss: 2.0122     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 32\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.9789     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.9617     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.9308     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.9025     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.8609     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 33\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.8451     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.8212     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.8174     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.7800     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.7516     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 34\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.7432     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.7242     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.6993     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.6774     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.6557     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 35\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.6529     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.6280     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.6217     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.6065     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.5979     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 36\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.5718     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.5618     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.5616     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.5501     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.5313     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 37\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.5262     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.5120     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.5182     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.5030     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.5062     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 38\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.4849     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.4772     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.4730     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.4563     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.4601     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 39\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.4617     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.4423     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.4441     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.4284     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.4297     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 40\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.4257     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.4201     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.4228     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.4115     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.4033     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 41\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.4043     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.3906     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.3876     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.3887     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.3772     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 42\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.3889     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.3691     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.3688     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.3668     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.3552     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 43\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.3508     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.3615     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.3474     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.3577     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.3569     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 44\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.3442     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.3417     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.3439     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.3435     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.3389     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 45\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.3257     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.3318     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.3328     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.3200     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.3238     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 46\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.3254     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.3270     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.3223     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.3307     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.3108     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 47\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.3172     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.3078     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.3117     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.3137     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.3053     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 48\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 3s - loss: 1.3065     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 3s - loss: 1.3152     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 3s - loss: 1.2919     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.3028     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2941     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 49\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2986     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2874     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2825     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2876     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2936     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 50\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2866     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2843     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2806     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2799     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2727     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 51\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2819     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2787     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2723     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2815     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2714     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 52\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2714     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2639     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2678     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2700     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2774     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 53\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2698     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2660     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2692     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2682     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2579     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 54\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2580     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2678     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2608     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2509     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2486     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 55\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2452     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2431     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2511     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2442     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2495     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 56\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2541     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2418     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2476     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2397     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2486     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 57\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2478     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2488     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2419     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2415     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2382     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 58\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2420     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2383     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2386     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2419     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2341     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 59\n",
      "Epoch 1/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2354     \n",
      "Epoch 2/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2292     \n",
      "Epoch 3/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2355     \n",
      "Epoch 4/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2320     \n",
      "Epoch 5/5\n",
      "8592/8592 [==============================] - 2s - loss: 1.2322     \n"
     ]
    }
   ],
   "source": [
    "# train the English model\n",
    "for iteration in range(1, 60):\n",
    "    print()\n",
    "    print('-' * 50)\n",
    "    print('Iteration', iteration)\n",
    "    model_eng.fit([X_train_eng, X_train_eng], X_train_labels_eng,\n",
    "              batch_size=128,\n",
    "              epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 5s - loss: 2.9363     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 3s - loss: 2.8583     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 3s - loss: 2.8491     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 3s - loss: 2.8370     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 3s - loss: 2.8334     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 3s - loss: 2.8328     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 3s - loss: 2.8232     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 3s - loss: 2.8244     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 3s - loss: 2.8228     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 3s - loss: 2.8248     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 3\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 3s - loss: 2.8203     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 3s - loss: 2.8208     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 3s - loss: 2.8135     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 3s - loss: 2.8149     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 3s - loss: 2.8095     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 4\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 3s - loss: 2.8098     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 3s - loss: 2.8078     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 3s - loss: 2.8104     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 3s - loss: 2.8076     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 3s - loss: 2.8044     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 5\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 3s - loss: 2.8031     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 3s - loss: 2.8074     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 3s - loss: 2.7973     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 3s - loss: 2.8001     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 3s - loss: 2.7989     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 6\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 3s - loss: 2.7971     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 3s - loss: 2.8016     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 3s - loss: 2.7938     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 3s - loss: 2.7934     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 3s - loss: 2.7967     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 7\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 3s - loss: 2.7959     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 3s - loss: 2.7892     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 3s - loss: 2.7882     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 3s - loss: 2.7904     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 3s - loss: 2.7886     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 8\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 3s - loss: 2.7894     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 3s - loss: 2.7856     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 3s - loss: 2.7849     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 3s - loss: 2.7871     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 3s - loss: 2.7812     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 9\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 3s - loss: 2.7794     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 3s - loss: 2.7810     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 3s - loss: 2.7805     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 4s - loss: 2.7761     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 3s - loss: 2.7784     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 10\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 3s - loss: 2.7741     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 3s - loss: 2.7747     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 3s - loss: 2.7725     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 3s - loss: 2.7712     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 3s - loss: 2.7743     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 11\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 3s - loss: 2.7684     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 3s - loss: 2.7682     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 3s - loss: 2.7697     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 3s - loss: 2.7667     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 3s - loss: 2.7650     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 12\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 3s - loss: 2.7654     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 3s - loss: 2.7701     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 3s - loss: 2.7652     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 3s - loss: 2.7606     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 3s - loss: 2.7643     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 13\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 3s - loss: 2.7634     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 3s - loss: 2.7605     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 4s - loss: 2.7548     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 4s - loss: 2.7583     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 3s - loss: 2.7590     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 14\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 3s - loss: 2.7565     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 4s - loss: 2.7556     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 3s - loss: 2.7547     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 2s - loss: 2.7523     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 2s - loss: 2.7517     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 15\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 2s - loss: 2.7597     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 2s - loss: 2.7525     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 2s - loss: 2.7488     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 2s - loss: 2.7474     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 2s - loss: 2.7495     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 16\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 2s - loss: 2.7463     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 2s - loss: 2.7463     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 2s - loss: 2.7554     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 2s - loss: 2.7500     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 2s - loss: 2.7456     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 17\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 2s - loss: 2.7487     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 2s - loss: 2.7407     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 2s - loss: 2.7397     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 2s - loss: 2.7388     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 2s - loss: 2.7387     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 18\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 2s - loss: 2.7396     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 2s - loss: 2.7379     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 2s - loss: 2.7333     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 2s - loss: 2.7363     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 2s - loss: 2.7313     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 19\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 2s - loss: 2.7352     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 2s - loss: 2.7338     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 2s - loss: 2.7344     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 2s - loss: 2.7297     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 2s - loss: 2.7283     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 20\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 4s - loss: 2.7309     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 3s - loss: 2.7263     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 2s - loss: 2.7260     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 4s - loss: 2.7249     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 3s - loss: 2.7287     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 21\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 3s - loss: 2.7259     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 2s - loss: 2.7326     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 2s - loss: 2.7224     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 3s - loss: 2.7214     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 2s - loss: 2.7149     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 22\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 3s - loss: 2.7187     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 2s - loss: 2.7170     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 2s - loss: 2.7138     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 3s - loss: 2.7131     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 2s - loss: 2.7153     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 23\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 2s - loss: 2.7155     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 2s - loss: 2.7106     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 2s - loss: 2.7073     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 2s - loss: 2.7033     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 3s - loss: 2.7113     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 24\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 2s - loss: 2.7052     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 3s - loss: 2.7038     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 3s - loss: 2.7071     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 3s - loss: 2.7074     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 3s - loss: 2.7004     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 25\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 2s - loss: 2.6986     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 3s - loss: 2.6959     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 2s - loss: 2.6996     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 2s - loss: 2.6907     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 3s - loss: 2.6921     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 26\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 3s - loss: 2.6877     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 3s - loss: 2.6837     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 2s - loss: 2.6809     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 2s - loss: 2.6838     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 2s - loss: 2.6842     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 27\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 2s - loss: 2.6783     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 3s - loss: 2.6762     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 2s - loss: 2.6709     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 2s - loss: 2.6663     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 2s - loss: 2.6615     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 28\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 2s - loss: 2.6708     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 2s - loss: 2.6601     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 2s - loss: 2.6578     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 2s - loss: 2.6521     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 2s - loss: 2.6485     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 29\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 2s - loss: 2.6507     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 2s - loss: 2.6411     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 2s - loss: 2.6372     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 3s - loss: 2.6333     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 3s - loss: 2.6249     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 30\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 3s - loss: 2.6259     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 3s - loss: 2.6100     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 3s - loss: 2.6058     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 2s - loss: 2.6036     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 2s - loss: 2.5938     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 31\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 2s - loss: 2.5850     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 3s - loss: 2.5794     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 3s - loss: 2.5764     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 3s - loss: 2.5573     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 2s - loss: 2.5546     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 32\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 2s - loss: 2.5408     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 3s - loss: 2.5374     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 3s - loss: 2.5404     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 3s - loss: 2.5355     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 2s - loss: 2.4986     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 33\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 3s - loss: 2.4948     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 3s - loss: 2.4760     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 4s - loss: 2.4841     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 3s - loss: 2.4539     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 2s - loss: 2.4455     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 34\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 2s - loss: 2.4369     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 2s - loss: 2.4350     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 3s - loss: 2.4058     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 3s - loss: 2.4072     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 3s - loss: 2.4239     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 35\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 3s - loss: 2.3939     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 2s - loss: 2.3517     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 3s - loss: 2.3357     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 3s - loss: 2.3175     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 3s - loss: 2.2971     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 36\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 3s - loss: 2.2719     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 3s - loss: 2.2631     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 2s - loss: 2.2390     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 3s - loss: 2.2145     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 3s - loss: 2.1836     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 37\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 2s - loss: 2.2087     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 3s - loss: 2.1671     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 3s - loss: 2.1502     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 3s - loss: 2.1068     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 3s - loss: 2.1371     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 38\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 3s - loss: 2.1636     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 3s - loss: 2.0790     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 3s - loss: 2.0547     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 4s - loss: 2.0572     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 3s - loss: 2.0168     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 39\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 2s - loss: 2.0518     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.9580     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.9422     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.9928     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 2s - loss: 2.0700     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 40\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.9268     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.8589     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.9130     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.8004     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.8373     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 41\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.8318     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.8321     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 3s - loss: 1.7944     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.8320     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.7449     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 42\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 3s - loss: 1.7464     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 3s - loss: 1.6990     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 3s - loss: 1.6774     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 3s - loss: 1.7441     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 3s - loss: 1.7043     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 43\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 3s - loss: 1.6746     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 3s - loss: 1.6504     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.6139     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.6848     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 3s - loss: 1.7930     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 44\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 4s - loss: 1.7401     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 4s - loss: 1.6731     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 4s - loss: 1.6301     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.6334     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.5617     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 45\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.6504     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 3s - loss: 1.5396     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 4s - loss: 1.6101     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 4s - loss: 1.5583     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 3s - loss: 1.5313     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 46\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.5193     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.5372     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.4849     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.4704     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.4485     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 47\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.4664     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.4539     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.5441     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.4682     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.4722     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 48\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.4978     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.5193     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.5326     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.4924     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.5483     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 49\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.5270     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.4783     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.4339     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.4472     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.4932     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 50\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.4375     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.4136     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.4100     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.4456     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.4478     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 51\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.5143     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.4976     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.4412     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.4265     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.4157     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 52\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.3973     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.4241     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.4274     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.3810     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.4252     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 53\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.4479     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.4193     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.4415     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.4470     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.4921     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 54\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 3s - loss: 1.4480     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.3941     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.3912     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.3830     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.3628     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 55\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.3693     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.3715     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.4316     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.3731     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.3697     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 56\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.3086     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.3853     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.3637     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.3636     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.3540     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 57\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.3693     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.3571     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.3413     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.3590     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.3343     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 58\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.3550     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.3412     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.3527     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2991     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.3392     \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 59\n",
      "Epoch 1/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.2782     \n",
      "Epoch 2/5\n",
      "9603/9603 [==============================] - 2s - loss: 1.3321     \n",
      "Epoch 3/5\n",
      "9603/9603 [==============================] - 3s - loss: 1.2936     \n",
      "Epoch 4/5\n",
      "9603/9603 [==============================] - 3s - loss: 1.3384     \n",
      "Epoch 5/5\n",
      "9603/9603 [==============================] - 3s - loss: 1.3239     \n"
     ]
    }
   ],
   "source": [
    "# train the French model\n",
    "for iteration in range(1, 60):\n",
    "    print()\n",
    "    print('-' * 50)\n",
    "    print('Iteration', iteration)\n",
    "    model_frn.fit([X_train_frn, X_train_frn], X_train_labels_frn,\n",
    "              batch_size=128,\n",
    "              epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the 200 test data\n",
    "test_data_200 = np.zeros((200, maxlen, len(chars)), dtype=np.bool)\n",
    "\n",
    "# Pick 100 substrings at random from each language\n",
    "eng_test_indices = np.random.randint(0, X_test_eng.shape[0], size=100)\n",
    "frn_test_indices = np.random.randint(0, X_test_frn.shape[0], size=100)\n",
    "\n",
    "# Fill the data\n",
    "test_data_200[:100] = X_test_eng[eng_test_indices,:,:]\n",
    "test_data_200[100:] = X_test_frn[frn_test_indices,:,:]\n",
    "\n",
    "# Create the labels\n",
    "test_labels_200 = np.concatenate(([1]*100, [0]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Vectorize test string\n",
    "def test_vectorization(test_string, maxlen, chars, char_indices):\n",
    "    test_string_data = []\n",
    "    # Break up test string\n",
    "    for ind in range(min(maxlen, len(test_string))):\n",
    "        test_string_data.append(test_string[:ind])\n",
    "    # Create X\n",
    "    X = np.zeros((len(test_string_data), maxlen, len(chars)), dtype=np.bool)\n",
    "    for i, test_string_entry in enumerate(test_string_data):\n",
    "        for t, char in enumerate(test_string_entry):\n",
    "            X[i, t, char_indices[char]] = 1\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/5 [=====>........................] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "test_predict_200 = np.zeros(200)\n",
    "test_y_hat_200 = np.zeros(200)\n",
    "\n",
    "for t in range(test_data_200.shape[0]):\n",
    "    letter_string = ''\n",
    "    for letter in range(test_data_200[t].shape[0]):\n",
    "        letter_ind = np.where(test_data_200[t,letter,:]==1)[0][0]\n",
    "        letter_string += chars[letter_ind]\n",
    "        if (len(letter_string) >= 5):\n",
    "            break\n",
    "    letter_string_vect = test_vectorization(letter_string, maxlen, chars, char_indices)\n",
    "    \n",
    "    test_predict_eng = model_eng.predict([letter_string_vect, letter_string_vect], batch_size=1, verbose=1)\n",
    "    test_predict_frn = model_frn.predict([letter_string_vect, letter_string_vect], batch_size=1, verbose=1)\n",
    "    total_prob_eng = 1\n",
    "    total_prob_frn = 1\n",
    "    for p in range(len(test_predict_eng)):\n",
    "        if len(np.where(test_data_200[t,p,:]==1)[0]) == 0:\n",
    "            break\n",
    "        char_ind = np.where(test_data_200[t,p,:]==1)[0][0]\n",
    "        # English probability\n",
    "        char_prob_eng = test_predict_eng[p, char_ind]\n",
    "        total_prob_eng *= char_prob_eng\n",
    "        # French probability\n",
    "        char_prob_frn = test_predict_frn[p, char_ind]\n",
    "        total_prob_frn *= char_prob_frn\n",
    "    prediction = 1 if (np.log(total_prob_eng) > np.log(total_prob_frn)) else 0\n",
    "    test_predict_200[t] = prediction\n",
    "    test_y_hat_200[t] = np.log(total_prob_eng) - np.log(total_prob_frn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.63\n"
     ]
    }
   ],
   "source": [
    "accuracy_vect = np.nonzero(test_labels_200 - test_predict_200)\n",
    "accuracy = 1 - (len(accuracy_vect[0]) / 200.)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAoMAAAFqCAYAAABhzVBZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUswwKEmSlGKGQUmSpBQzDEqSJKXY/wc5rPDHaBsVKAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x164711c88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Code from\n",
    "# http://stackoverflow.com/questions/42894871/how-to-plot-multiple-roc-curves-in-one-plot-with-legend-and-auc-scores-in-python\n",
    "\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "plt.figure(0).clf()\n",
    "\n",
    "auc = metrics.roc_auc_score(test_labels_200, test_y_hat_200)\n",
    "fpr, tpr, thresholds = metrics.roc_curve(test_labels_200, test_y_hat_200)\n",
    "plt.semilogx(basex = math.e)\n",
    "plt.plot(fpr, tpr, label=\"AUC=\"+str(auc))\n",
    "#plt.plot([0, 1], [0, 1], color='gray')\n",
    "\n",
    "plt.legend(loc=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Surprisingly, the bidirectional LSTM did not clearly outperform the regular LSTM.  While it had a comparable performance, it did not perform as highly as expected.  We saw accuracies ranging from the mid-50% to the 63% shown here.  The AUC is respectable.  Variations in the performance are likely due to randomly sampling 100 strings per language from the test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra Credit - Larger Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We were curious as to whether or not a larger dataset might result in better predictive outcomes.  In order to test this, we needed a much longer document for which there were high quality translations into different languages.  We found that the Vatican makes available on its site and in several languages the Compendium to the Catechism of the Catholic Church.  We took a portion of the English and French translations of this document.  We do not profess that our data gathering process or the documents themselves were perfect, primarily with regard to '\\n' characters.  Nevertheless, it should be of sufficient quality to test the question at hand.  The English and French Compendium documents were 260 KB and 275KB, respectively, as opposed to the 11 KB and 12 KB human rights documents.  The model performed quite well, achieving accuracies in the mid- to high-60% and a nice AUC value.  The performance was not vastly superior to that of LSTMs with smaller datasets, but it did seem to be among the best performing models we had.\n",
    "\n",
    "Due to the size of the documents, training the models on them took much longer.  We did this in a separate notebook so we could work on several parts of the project concurrently.  Due to the time required to run it again were we to put it here, we decided to turn it in as a separate notebook.  Please see that notebook for the code and results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
