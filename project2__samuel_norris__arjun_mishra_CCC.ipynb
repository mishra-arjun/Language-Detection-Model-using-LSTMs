{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROJECT 2 - LSTM\n",
    "\n",
    "## Samuel Norris and Arjun Mishra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please do not start with this notebook.  You should be referred to this notebook by the last section of the main project notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The text data for these models is a portion of the Compendium to the Catechism of the Catholic Church.  The full text in each language can be found at:\n",
    "1. http://www.vatican.va/archive/compendium_ccc/documents/archive_2005_compendium-ccc_en.html (English)\n",
    "2. http://www.vatican.va/archive/compendium_ccc/documents/archive_2005_compendium-ccc_fr.html (French)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Corpus Length:\t 258023\n",
      "French Corpus Length:\t 261425\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries (some imported later in the code) and read in data\n",
    "\n",
    "from __future__ import print_function\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils.data_utils import get_file\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "\n",
    "path_eng = 'compendium_CCC_edited_english.txt'\n",
    "text_eng = open(path_eng).read().lower()\n",
    "print('English Corpus Length:\\t', len(text_eng))\n",
    "\n",
    "path_frn = 'compendium_CCC_edited_french.txt'\n",
    "text_frn = open(path_frn).read().lower()\n",
    "print('French Corpus Length:\\t', len(text_frn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Chars:\t 77\n"
     ]
    }
   ],
   "source": [
    "# Get chars from two texts\n",
    "chars_from_eng = sorted(list(set(text_eng)))\n",
    "chars_from_frn = sorted(list(set(text_frn)))\n",
    "\n",
    "# Combine chars from two languages into one chars list\n",
    "#######################\n",
    "# Code between hash lines taken from \n",
    "# http://stackoverflow.com/questions/2151517/pythonic-way-to-create-union-of-all-values-contained-in-multiple-lists\n",
    "results_list = [chars_from_eng, chars_from_frn]\n",
    "chars = list(set().union(*results_list))\n",
    "#######################\n",
    "\n",
    "# Get dictionaries of chars and their index in the chars list\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "print('Total Chars:\\t', len(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English 5-char sequences:\t 258018\n",
      "French 5-char sequences:\t 261420\n"
     ]
    }
   ],
   "source": [
    "# Break up English text into 5 char segments, shifting one char at a\n",
    "# time when making new segments\n",
    "maxlen = 5\n",
    "step = 1\n",
    "char5_strings_eng = []\n",
    "next_chars_eng = []\n",
    "for i in range(0, len(text_eng) - maxlen, step):\n",
    "    char5_strings_eng.append(text_eng[i: i + maxlen])\n",
    "    next_chars_eng.append(text_eng[i + maxlen])\n",
    "print('English 5-char sequences:\\t', len(char5_strings_eng))\n",
    "\n",
    "# Break up French text into 5 char segments, shifting one char at a\n",
    "# time when making new segments\n",
    "maxlen = 5\n",
    "step = 1\n",
    "char5_strings_frn = []\n",
    "next_chars_frn = []\n",
    "for i in range(0, len(text_frn) - maxlen, step):\n",
    "    char5_strings_frn.append(text_frn[i: i + maxlen])\n",
    "    next_chars_frn.append(text_frn[i + maxlen])\n",
    "print('French 5-char sequences:\\t', len(char5_strings_frn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the labels for the datasets\n",
    "# 1=English, 0=French\n",
    "labels_eng = np.array([1]*len(char5_strings_eng))\n",
    "labels_frn = np.array([0]*len(char5_strings_frn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_predict, learning_curve\n",
    "\n",
    "# Do an 80/20 split to get training and test data for both English and French\n",
    "training_data_eng, testing_data_eng, training_labels_eng, testing_labels_eng = train_test_split(\n",
    "        char5_strings_eng, labels_eng, test_size=0.2, random_state=0)\n",
    "\n",
    "training_data_frn, testing_data_frn, training_labels_frn, testing_labels_frn = train_test_split(\n",
    "        char5_strings_frn, labels_frn, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Method to vectorize a dataset\n",
    "def vectorization(char5_strings, maxlen, chars, char_indices, next_chars):\n",
    "    X = np.zeros((len(char5_strings), maxlen, len(chars)), dtype=np.bool)\n",
    "    y = np.zeros((len(char5_strings), len(chars)), dtype=np.bool)\n",
    "    for i, char5_string in enumerate(char5_strings):\n",
    "        for t, char in enumerate(char5_string):\n",
    "            X[i, t, char_indices[char]] = 1\n",
    "        y[i, char_indices[next_chars[i]]] = 1\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_eng, X_train_labels_eng = vectorization(training_data_eng, maxlen, chars, char_indices, next_chars_eng)\n",
    "X_test_eng, X_test_labels_eng = vectorization(testing_data_eng, maxlen, chars, char_indices, next_chars_eng)\n",
    "\n",
    "X_train_frn, X_train_labels_frn = vectorization(training_data_frn, maxlen, chars, char_indices, next_chars_frn)\n",
    "X_test_frn, X_test_labels_frn = vectorization(testing_data_frn, maxlen, chars, char_indices, next_chars_frn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building English model\n",
      "Building French model\n"
     ]
    }
   ],
   "source": [
    "# Build the English model: a single LSTM\n",
    "print('Building English model')\n",
    "model_eng = Sequential()\n",
    "model_eng.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "model_eng.add(Dense(len(chars)))\n",
    "model_eng.add(Activation('softmax'))\n",
    "\n",
    "optimizer = RMSprop(lr=0.01)\n",
    "model_eng.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
    "\n",
    "\n",
    "# Build the French model: a single LSTM\n",
    "print('Building French model')\n",
    "model_frn = Sequential()\n",
    "model_frn.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "model_frn.add(Dense(len(chars)))\n",
    "model_frn.add(Activation('softmax'))\n",
    "\n",
    "model_frn.compile(loss='categorical_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1\n",
      "Epoch 1/3\n",
      "206414/206414 [==============================] - 39s - loss: 3.1000    \n",
      "Epoch 2/3\n",
      "206414/206414 [==============================] - 39s - loss: 3.0928    \n",
      "Epoch 3/3\n",
      "206414/206414 [==============================] - 38s - loss: 3.0919    \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2\n",
      "Epoch 1/3\n",
      "206414/206414 [==============================] - 37s - loss: 3.0910    \n",
      "Epoch 2/3\n",
      "206414/206414 [==============================] - 37s - loss: 3.0920    \n",
      "Epoch 3/3\n",
      "206414/206414 [==============================] - 37s - loss: 3.0928    \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 3\n",
      "Epoch 1/3\n",
      "206414/206414 [==============================] - 37s - loss: 3.0929    \n",
      "Epoch 2/3\n",
      "206414/206414 [==============================] - 37s - loss: 3.0939    \n",
      "Epoch 3/3\n",
      "206414/206414 [==============================] - 37s - loss: 3.0937    \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 4\n",
      "Epoch 1/3\n",
      "206414/206414 [==============================] - 43s - loss: 3.0928    \n",
      "Epoch 2/3\n",
      "206414/206414 [==============================] - 44s - loss: 3.0937    \n",
      "Epoch 3/3\n",
      "206414/206414 [==============================] - 44s - loss: 3.0936    \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 5\n",
      "Epoch 1/3\n",
      "206414/206414 [==============================] - 44s - loss: 3.0942    \n",
      "Epoch 2/3\n",
      "206414/206414 [==============================] - 44s - loss: 3.0931    \n",
      "Epoch 3/3\n",
      "206414/206414 [==============================] - 44s - loss: 3.0931    \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 6\n",
      "Epoch 1/3\n",
      "206414/206414 [==============================] - 44s - loss: 3.0927    \n",
      "Epoch 2/3\n",
      "206414/206414 [==============================] - 43s - loss: 3.0925    \n",
      "Epoch 3/3\n",
      "206414/206414 [==============================] - 40s - loss: 3.0928    \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 7\n",
      "Epoch 1/3\n",
      "206414/206414 [==============================] - 40s - loss: 3.0925    \n",
      "Epoch 2/3\n",
      "206414/206414 [==============================] - 39s - loss: 3.0922    \n",
      "Epoch 3/3\n",
      "206414/206414 [==============================] - 40s - loss: 3.0915    \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 8\n",
      "Epoch 1/3\n",
      "206414/206414 [==============================] - 40s - loss: 3.0919    \n",
      "Epoch 2/3\n",
      "206414/206414 [==============================] - 40s - loss: 3.0912    \n",
      "Epoch 3/3\n",
      "206414/206414 [==============================] - 40s - loss: 3.0923    \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 9\n",
      "Epoch 1/3\n",
      "206414/206414 [==============================] - 40s - loss: 3.0916    \n",
      "Epoch 2/3\n",
      "206414/206414 [==============================] - 40s - loss: 3.0922    \n",
      "Epoch 3/3\n",
      "206414/206414 [==============================] - 40s - loss: 3.0917    \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 10\n",
      "Epoch 1/3\n",
      "206414/206414 [==============================] - 40s - loss: 3.0912    \n",
      "Epoch 2/3\n",
      "206414/206414 [==============================] - 44s - loss: 3.0920    \n",
      "Epoch 3/3\n",
      "206414/206414 [==============================] - 43s - loss: 3.0922    \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 11\n",
      "Epoch 1/3\n",
      "206414/206414 [==============================] - 43s - loss: 3.0915    \n",
      "Epoch 2/3\n",
      "206414/206414 [==============================] - 45s - loss: 3.0913    \n",
      "Epoch 3/3\n",
      "206414/206414 [==============================] - 44s - loss: 3.0915    \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 12\n",
      "Epoch 1/3\n",
      "206414/206414 [==============================] - 44s - loss: 3.0914    \n",
      "Epoch 2/3\n",
      "206414/206414 [==============================] - 44s - loss: 3.0909    \n",
      "Epoch 3/3\n",
      "206414/206414 [==============================] - 44s - loss: 3.0903    \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 13\n",
      "Epoch 1/3\n",
      "206414/206414 [==============================] - 46s - loss: 3.0911    \n",
      "Epoch 2/3\n",
      "206414/206414 [==============================] - 46s - loss: 3.0913    \n",
      "Epoch 3/3\n",
      "206414/206414 [==============================] - 46s - loss: 3.0908    \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 14\n",
      "Epoch 1/3\n",
      "206414/206414 [==============================] - 46s - loss: 3.0907    \n",
      "Epoch 2/3\n",
      "206414/206414 [==============================] - 45s - loss: 3.0919    \n",
      "Epoch 3/3\n",
      "206414/206414 [==============================] - 40s - loss: 3.0892    \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 15\n",
      "Epoch 1/3\n",
      "206414/206414 [==============================] - 41s - loss: 3.0900    \n",
      "Epoch 2/3\n",
      "206414/206414 [==============================] - 40s - loss: 3.0902    \n",
      "Epoch 3/3\n",
      "206414/206414 [==============================] - 41s - loss: 3.0903    \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 16\n",
      "Epoch 1/3\n",
      "206414/206414 [==============================] - 41s - loss: 3.0895    \n",
      "Epoch 2/3\n",
      "206414/206414 [==============================] - 40s - loss: 3.0891    \n",
      "Epoch 3/3\n",
      "206414/206414 [==============================] - 40s - loss: 3.0899    \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 17\n",
      "Epoch 1/3\n",
      "206414/206414 [==============================] - 44s - loss: 3.0884    \n",
      "Epoch 2/3\n",
      "206414/206414 [==============================] - 44s - loss: 3.0887    \n",
      "Epoch 3/3\n",
      "206414/206414 [==============================] - 44s - loss: 3.0891    \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 18\n",
      "Epoch 1/3\n",
      "206414/206414 [==============================] - 44s - loss: 3.0883    \n",
      "Epoch 2/3\n",
      "206414/206414 [==============================] - 44s - loss: 3.0877    \n",
      "Epoch 3/3\n",
      "206414/206414 [==============================] - 45s - loss: 3.0884    \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 19\n",
      "Epoch 1/3\n",
      "206414/206414 [==============================] - 44s - loss: 3.0894    \n",
      "Epoch 2/3\n",
      "206414/206414 [==============================] - 44s - loss: 3.0886    \n",
      "Epoch 3/3\n",
      "206414/206414 [==============================] - 44s - loss: 3.0877    \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 20\n",
      "Epoch 1/3\n",
      "206414/206414 [==============================] - 44s - loss: 3.0885    \n",
      "Epoch 2/3\n",
      "206414/206414 [==============================] - 44s - loss: 3.0870    \n",
      "Epoch 3/3\n",
      "206414/206414 [==============================] - 44s - loss: 3.0875    \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 21\n",
      "Epoch 1/3\n",
      "206414/206414 [==============================] - 44s - loss: 3.0870    \n",
      "Epoch 2/3\n",
      "206414/206414 [==============================] - 44s - loss: 3.0877    \n",
      "Epoch 3/3\n",
      "206414/206414 [==============================] - 44s - loss: 3.0875    \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 22\n",
      "Epoch 1/3\n",
      "206414/206414 [==============================] - 44s - loss: 3.0869    \n",
      "Epoch 2/3\n",
      "206414/206414 [==============================] - 44s - loss: 3.0877    \n",
      "Epoch 3/3\n",
      "206414/206414 [==============================] - 44s - loss: 3.0865    \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 23\n",
      "Epoch 1/3\n",
      "206414/206414 [==============================] - 44s - loss: 3.0880    \n",
      "Epoch 2/3\n",
      "206414/206414 [==============================] - 45s - loss: 3.0877    \n",
      "Epoch 3/3\n",
      "206414/206414 [==============================] - 44s - loss: 3.0867    \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 24\n",
      "Epoch 1/3\n",
      "206414/206414 [==============================] - 44s - loss: 3.0861    \n",
      "Epoch 2/3\n",
      "206414/206414 [==============================] - 44s - loss: 3.0859    \n",
      "Epoch 3/3\n",
      "206414/206414 [==============================] - 45s - loss: 3.0863    \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 25\n",
      "Epoch 1/3\n",
      "206414/206414 [==============================] - 44s - loss: 3.0861    \n",
      "Epoch 2/3\n",
      "206414/206414 [==============================] - 44s - loss: 3.0855    \n",
      "Epoch 3/3\n",
      "206414/206414 [==============================] - 45s - loss: 3.0861    \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 26\n",
      "Epoch 1/3\n",
      "206414/206414 [==============================] - 43s - loss: 3.0854    \n",
      "Epoch 2/3\n",
      "206414/206414 [==============================] - 43s - loss: 3.0876    \n",
      "Epoch 3/3\n",
      "206414/206414 [==============================] - 44s - loss: 3.0872    \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 27\n",
      "Epoch 1/3\n",
      "206414/206414 [==============================] - 43s - loss: 3.0874    \n",
      "Epoch 2/3\n",
      "206414/206414 [==============================] - 43s - loss: 3.0855    \n",
      "Epoch 3/3\n",
      "206414/206414 [==============================] - 43s - loss: 3.0931    \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 28\n",
      "Epoch 1/3\n",
      "206414/206414 [==============================] - 43s - loss: 3.0854    \n",
      "Epoch 2/3\n",
      "206414/206414 [==============================] - 43s - loss: 3.0853    \n",
      "Epoch 3/3\n",
      "206414/206414 [==============================] - 43s - loss: 3.0854    \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 29\n",
      "Epoch 1/3\n",
      "206414/206414 [==============================] - 43s - loss: 3.0860    \n",
      "Epoch 2/3\n",
      "206414/206414 [==============================] - 43s - loss: 3.0848    \n",
      "Epoch 3/3\n",
      "206414/206414 [==============================] - 43s - loss: 3.0874    \n"
     ]
    }
   ],
   "source": [
    "# train the English model\n",
    "for iteration in range(1, 30): # Make it 26\n",
    "    print()\n",
    "    print('-' * 50)\n",
    "    print('Iteration', iteration)\n",
    "    model_eng.fit(X_train_eng, X_train_labels_eng,\n",
    "              batch_size=128,\n",
    "              epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1\n",
      "Epoch 1/3\n",
      "209136/209136 [==============================] - 44s - loss: 3.1439    \n",
      "Epoch 2/3\n",
      "209136/209136 [==============================] - 44s - loss: 3.1371    \n",
      "Epoch 3/3\n",
      "209136/209136 [==============================] - 43s - loss: 3.1361    \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2\n",
      "Epoch 1/3\n",
      "209136/209136 [==============================] - 44s - loss: 3.1376    \n",
      "Epoch 2/3\n",
      "209136/209136 [==============================] - 45s - loss: 3.1402    \n",
      "Epoch 3/3\n",
      "209136/209136 [==============================] - 45s - loss: 3.1406    \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 3\n",
      "Epoch 1/3\n",
      "209136/209136 [==============================] - 43s - loss: 3.1423    \n",
      "Epoch 2/3\n",
      "209136/209136 [==============================] - 43s - loss: 3.1418    \n",
      "Epoch 3/3\n",
      "209136/209136 [==============================] - 43s - loss: 3.1414    \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 4\n",
      "Epoch 1/3\n",
      "209136/209136 [==============================] - 46s - loss: 3.1415    \n",
      "Epoch 2/3\n",
      "209136/209136 [==============================] - 44s - loss: 3.1428    \n",
      "Epoch 3/3\n",
      "209136/209136 [==============================] - 46s - loss: 3.1416    \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 5\n",
      "Epoch 1/3\n",
      "209136/209136 [==============================] - 45s - loss: 3.1421    \n",
      "Epoch 2/3\n",
      "209136/209136 [==============================] - 45s - loss: 3.1422    \n",
      "Epoch 3/3\n",
      "209136/209136 [==============================] - 45s - loss: 3.1415    \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 6\n",
      "Epoch 1/3\n",
      "209136/209136 [==============================] - 44s - loss: 3.1412    \n",
      "Epoch 2/3\n",
      "209136/209136 [==============================] - 47s - loss: 3.1420    \n",
      "Epoch 3/3\n",
      "209136/209136 [==============================] - 45s - loss: 3.1414    \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 7\n",
      "Epoch 1/3\n",
      "209136/209136 [==============================] - 45s - loss: 3.1416    \n",
      "Epoch 2/3\n",
      "209136/209136 [==============================] - 44s - loss: 3.1417    \n",
      "Epoch 3/3\n",
      "209136/209136 [==============================] - 45s - loss: 3.1410    \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 8\n",
      "Epoch 1/3\n",
      "209136/209136 [==============================] - 45s - loss: 3.1407    \n",
      "Epoch 2/3\n",
      "209136/209136 [==============================] - 45s - loss: 3.1407    \n",
      "Epoch 3/3\n",
      "209136/209136 [==============================] - 45s - loss: 3.1407    \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 9\n",
      "Epoch 1/3\n",
      "209136/209136 [==============================] - 44s - loss: 3.1408    \n",
      "Epoch 2/3\n",
      "209136/209136 [==============================] - 44s - loss: 3.1407    \n",
      "Epoch 3/3\n",
      "209136/209136 [==============================] - 45s - loss: 3.1408    \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 10\n",
      "Epoch 1/3\n",
      "209136/209136 [==============================] - 45s - loss: 3.1409    \n",
      "Epoch 2/3\n",
      "209136/209136 [==============================] - 45s - loss: 3.1414    \n",
      "Epoch 3/3\n",
      "209136/209136 [==============================] - 45s - loss: 3.1409    \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 11\n",
      "Epoch 1/3\n",
      "209136/209136 [==============================] - 42s - loss: 3.1411    \n",
      "Epoch 2/3\n",
      "209136/209136 [==============================] - 43s - loss: 3.1399    \n",
      "Epoch 3/3\n",
      "209136/209136 [==============================] - 46s - loss: 3.1403    \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 12\n",
      "Epoch 1/3\n",
      "209136/209136 [==============================] - 43s - loss: 3.1396    \n",
      "Epoch 2/3\n",
      "209136/209136 [==============================] - 43s - loss: 3.1398    \n",
      "Epoch 3/3\n",
      "209136/209136 [==============================] - 43s - loss: 3.1396    \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 13\n",
      "Epoch 1/3\n",
      "209136/209136 [==============================] - 44s - loss: 3.1397    \n",
      "Epoch 2/3\n",
      "209136/209136 [==============================] - 43s - loss: 3.1402    \n",
      "Epoch 3/3\n",
      "209136/209136 [==============================] - 44s - loss: 3.1398    \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 14\n",
      "Epoch 1/3\n",
      "209136/209136 [==============================] - 43s - loss: 3.1397    \n",
      "Epoch 2/3\n",
      "209136/209136 [==============================] - 41s - loss: 3.1398    \n",
      "Epoch 3/3\n",
      "209136/209136 [==============================] - 41s - loss: 3.1402    \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 15\n",
      "Epoch 1/3\n",
      "209136/209136 [==============================] - 41s - loss: 3.1407    \n",
      "Epoch 2/3\n",
      "209136/209136 [==============================] - 41s - loss: 3.1392    \n",
      "Epoch 3/3\n",
      "209136/209136 [==============================] - 41s - loss: 3.1423    \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 16\n",
      "Epoch 1/3\n",
      "209136/209136 [==============================] - 41s - loss: 3.1429    \n",
      "Epoch 2/3\n",
      "209136/209136 [==============================] - 41s - loss: 3.1399    \n",
      "Epoch 3/3\n",
      "209136/209136 [==============================] - 41s - loss: 3.1398    \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 17\n",
      "Epoch 1/3\n",
      "209136/209136 [==============================] - 41s - loss: 3.1419    \n",
      "Epoch 2/3\n",
      "209136/209136 [==============================] - 42s - loss: 3.1412    \n",
      "Epoch 3/3\n",
      "209136/209136 [==============================] - 41s - loss: 3.1402    \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 18\n",
      "Epoch 1/3\n",
      "209136/209136 [==============================] - 41s - loss: 3.1389    \n",
      "Epoch 2/3\n",
      "209136/209136 [==============================] - 41s - loss: 3.1399    \n",
      "Epoch 3/3\n",
      "209136/209136 [==============================] - 41s - loss: 3.1400    \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 19\n",
      "Epoch 1/3\n",
      "209136/209136 [==============================] - 41s - loss: 3.1414    \n",
      "Epoch 2/3\n",
      "209136/209136 [==============================] - 41s - loss: 3.1410    \n",
      "Epoch 3/3\n",
      "209136/209136 [==============================] - 41s - loss: 3.1380    \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 20\n",
      "Epoch 1/3\n",
      "209136/209136 [==============================] - 41s - loss: 3.1393    \n",
      "Epoch 2/3\n",
      "209136/209136 [==============================] - 41s - loss: 3.1392    \n",
      "Epoch 3/3\n",
      "209136/209136 [==============================] - 42s - loss: 3.1399    \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 21\n",
      "Epoch 1/3\n",
      "209136/209136 [==============================] - 42s - loss: 3.1386    \n",
      "Epoch 2/3\n",
      "209136/209136 [==============================] - 41s - loss: 3.1380    \n",
      "Epoch 3/3\n",
      "209136/209136 [==============================] - 41s - loss: 3.1379    \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 22\n",
      "Epoch 1/3\n",
      "209136/209136 [==============================] - 42s - loss: 3.1388    \n",
      "Epoch 2/3\n",
      "209136/209136 [==============================] - 44s - loss: 3.1387    \n",
      "Epoch 3/3\n",
      "209136/209136 [==============================] - 42s - loss: 3.1388    \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 23\n",
      "Epoch 1/3\n",
      "209136/209136 [==============================] - 41s - loss: 3.1412    \n",
      "Epoch 2/3\n",
      "209136/209136 [==============================] - 40s - loss: 3.1399    \n",
      "Epoch 3/3\n",
      "209136/209136 [==============================] - 39s - loss: 3.1394    \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 24\n",
      "Epoch 1/3\n",
      "209136/209136 [==============================] - 42s - loss: 3.1390    \n",
      "Epoch 2/3\n",
      "209136/209136 [==============================] - 40s - loss: 3.1393    \n",
      "Epoch 3/3\n",
      "209136/209136 [==============================] - 45s - loss: 3.1383    \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 25\n",
      "Epoch 1/3\n",
      "209136/209136 [==============================] - 43s - loss: 3.1396    \n",
      "Epoch 2/3\n",
      "209136/209136 [==============================] - 43s - loss: 3.1393    \n",
      "Epoch 3/3\n",
      "209136/209136 [==============================] - 42s - loss: 3.1396    \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 26\n",
      "Epoch 1/3\n",
      "209136/209136 [==============================] - 40s - loss: 3.1402    \n",
      "Epoch 2/3\n",
      "209136/209136 [==============================] - 43s - loss: 3.1385    \n",
      "Epoch 3/3\n",
      "209136/209136 [==============================] - 42s - loss: 3.1401    \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 27\n",
      "Epoch 1/3\n",
      "209136/209136 [==============================] - 40s - loss: 3.1397    \n",
      "Epoch 2/3\n",
      "209136/209136 [==============================] - 40s - loss: 3.1408    \n",
      "Epoch 3/3\n",
      "209136/209136 [==============================] - 41s - loss: 3.1392    \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 28\n",
      "Epoch 1/3\n",
      "209136/209136 [==============================] - 38s - loss: 3.1411    \n",
      "Epoch 2/3\n",
      "209136/209136 [==============================] - 41s - loss: 3.1383    \n",
      "Epoch 3/3\n",
      "209136/209136 [==============================] - 48s - loss: 3.1383    \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 29\n",
      "Epoch 1/3\n",
      "209136/209136 [==============================] - 40s - loss: 3.1388    \n",
      "Epoch 2/3\n",
      "209136/209136 [==============================] - 41s - loss: 3.1379    \n",
      "Epoch 3/3\n",
      "209136/209136 [==============================] - 41s - loss: 3.1383    \n"
     ]
    }
   ],
   "source": [
    "# train the French model\n",
    "for iteration in range(1, 30): # Make this 26\n",
    "    print()\n",
    "    print('-' * 50)\n",
    "    print('Iteration', iteration)\n",
    "    model_frn.fit(X_train_frn, X_train_labels_frn,\n",
    "              batch_size=128,\n",
    "              epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create the 200 test data\n",
    "test_data_200 = np.zeros((200, maxlen, len(chars)), dtype=np.bool)\n",
    "\n",
    "# Pick 100 substrings at random from each language\n",
    "eng_test_indices = np.random.randint(0, X_test_eng.shape[0], size=100)\n",
    "frn_test_indices = np.random.randint(0, X_test_frn.shape[0], size=100)\n",
    "\n",
    "# Fill the data\n",
    "test_data_200[:100] = X_test_eng[eng_test_indices,:,:]\n",
    "test_data_200[100:] = X_test_frn[frn_test_indices,:,:]\n",
    "\n",
    "# Create the labels\n",
    "test_labels_200 = np.concatenate(([1]*100, [0]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Vectorize test string\n",
    "def test_vectorization(test_string, maxlen, chars, char_indices):\n",
    "    # Create array to handle broken up test string\n",
    "    test_string_data = []\n",
    "    \n",
    "    # Break up test string\n",
    "    for ind in range(min(maxlen, len(test_string))):\n",
    "        test_string_data.append(test_string[:ind])\n",
    "   \n",
    "    # Create X\n",
    "    X = np.zeros((len(test_string_data), maxlen, len(chars)), dtype=np.bool)\n",
    "    for i, test_string_entry in enumerate(test_string_data):\n",
    "        for t, char in enumerate(test_string_entry):\n",
    "            X[i, t, char_indices[char]] = 1\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/5 [=====>........................] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "test_predict_200 = np.zeros(200)\n",
    "test_y_hat_200 = np.zeros(200)\n",
    "\n",
    "for t in range(test_data_200.shape[0]):\n",
    "    letter_string = ''\n",
    "    for letter in range(maxlen):\n",
    "        letter_ind = np.where(test_data_200[t,letter,:]==1)[0][0]\n",
    "        letter_string += chars[letter_ind]\n",
    "    letter_string_vect = test_vectorization(letter_string, maxlen, chars, char_indices)\n",
    "    \n",
    "    test_predict_eng = model_eng.predict(letter_string_vect, batch_size=1, verbose=1)\n",
    "    test_predict_frn = model_frn.predict(letter_string_vect, batch_size=1, verbose=1)\n",
    "    total_prob_eng = 1\n",
    "    total_prob_frn = 1\n",
    "    for p in range(len(test_predict_eng)):\n",
    "        \"\"\"if len(np.where(test_data_200[t,p,:]==1)[0]) == 0:\n",
    "            print('BREAK')\n",
    "            break\"\"\"\n",
    "        char_ind = np.where(test_data_200[t,p,:]==1)[0][0]\n",
    "        # English probability\n",
    "        char_prob_eng = test_predict_eng[p, char_ind]\n",
    "        total_prob_eng *= char_prob_eng\n",
    "        # French probability\n",
    "        char_prob_frn = test_predict_frn[p, char_ind]\n",
    "        total_prob_frn *= char_prob_frn\n",
    "    prediction = 1 if (np.log(total_prob_eng) > np.log(total_prob_frn)) else 0\n",
    "    test_predict_200[t] = prediction\n",
    "    test_y_hat_200[t] = np.log(total_prob_eng) - np.log(total_prob_frn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6950000000000001\n"
     ]
    }
   ],
   "source": [
    "accuracy_vect = np.nonzero(test_labels_200 - test_predict_200)\n",
    "accuracy = 1 - (len(accuracy_vect[0]) / 200.)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAoMAAAFqCAYAAABhzVBZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12462da90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Code from\n",
    "# http://stackoverflow.com/questions/42894871/how-to-plot-multiple-roc-curves-in-one-plot-with-legend-and-auc-scores-in-python\n",
    "\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "plt.figure(0).clf()\n",
    "\n",
    "auc = metrics.roc_auc_score(test_labels_200, test_y_hat_200)\n",
    "fpr, tpr, thresholds = metrics.roc_curve(test_labels_200, test_y_hat_200)\n",
    "plt.semilogx(basex = math.e)\n",
    "plt.plot(fpr, tpr, label=\"AUC=\"+str(auc))\n",
    "#plt.plot([0, 1], [0, 1], color='gray')\n",
    "\n",
    "plt.legend(loc=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy achieved here was superior to the basic model assigned in this project.  We are not surprised by this fact, as much more training data was used.  The AUC was also very nice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
